window.__NUXT__=(function(a,b,c,d,e,f){return {staticAssetsBase:"\u002F_nuxt\u002Fstatic\u002F1634315825",layout:"default",error:a,state:{currentArticle:{type_of:"article",id:821876,title:"Decouple your DAGs with an event-driven architecture on AWS",description:"Introduction   Applying domain-driven design and an event-driven architecture to the...",readable_publish_date:"Sep 13",slug:"decouple-your-dags-with-an-event-driven-architecture-on-aws-bk",path:"\u002Faws-builders\u002Fdecouple-your-dags-with-an-event-driven-architecture-on-aws-bk",url:c,comments_count:0,public_reactions_count:d,collection_id:a,published_timestamp:b,positive_reactions_count:d,cover_image:"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--0ZDI18D0--\u002Fc_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Farticles\u002Fbq3qyg9cwe4zqnxwtgov.jpg",social_image:"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--2DDu8gMi--\u002Fc_imagga_scale,f_auto,fl_progressive,h_500,q_auto,w_1000\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Farticles\u002Fbq3qyg9cwe4zqnxwtgov.jpg",canonical_url:c,created_at:"2021-09-12T21:56:01Z",edited_at:a,crossposted_at:a,published_at:b,last_comment_at:b,reading_time_minutes:4,tag_list:"aws, eventdriven, serverless",tags:["aws","eventdriven","serverless"],body_html:"\u003Ch1\u003E\n  \u003Ca name=\"introduction\" href=\"#introduction\"\u003E\n  \u003C\u002Fa\u003E\n  Introduction\n\u003C\u002Fh1\u003E\n\n\u003Cp\u003EApplying domain-driven design and an event-driven architecture to the orchestration of our services has given our teams some very practical benefits in their day-to-day work on development and support. \u003C\u002Fp\u003E\n\n\u003Ch1\u003E\n  \u003Ca name=\"the-problem\" href=\"#the-problem\"\u003E\n  \u003C\u002Fa\u003E\n  The Problem\n\u003C\u002Fh1\u003E\n\n\u003Cp\u003EUp until recently, we ran our main scoring job in one big DAG running in Airflow. This DAG calls services developed and maintained by at least 3 separate teams. With this setup, we were tightly coupling our systems, our processes (on-call, support) and our development and technology choices.\u003C\u002Fp\u003E\n\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--eI_cboKy--\u002Fc_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Farticles\u002Fds0z3wyluo28u83p0tp6.png\" class=\"article-body-image-wrapper\"\u003E\u003Cimg src=\"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--eI_cboKy--\u002Fc_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Farticles\u002Fds0z3wyluo28u83p0tp6.png\" alt=\"Alt Text\" loading=\"lazy\"\u003E\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\n\u003Cp\u003EIn practice, here are a couple of real world problems we were running into:\u003C\u002Fp\u003E\n\n\u003Cp\u003E1) The upstream team had several variations of their steps within the DAG. Each variation needed to have our teams steps copied and maintained in separate DAGs. Decoupling allows us to keep all our steps in a single DAG and to know where exactly our services are being orchestrated from.\u003Cbr\u003E\n2) The decision to use Airflow was made by the upstream team as it made sense for their skills and technologies. Decoupling will also allow us to use a technology that may be better suited to our teams skills and technologies. For example, we could move to Step Functions if we wanted. We will not be bound to another team or domains technology choices.\u003Cbr\u003E\n3) In addition to being on a mailing list for all alerts from the DAG, having to troubleshoot any failure may involve going through the larger DAG. While this may seem minor, situations like these can take a toll on a developer's productivity. Having our own separate DAG allows us to focus on our own services.\u003C\u002Fp\u003E\n\n\u003Ch1\u003E\n  \u003Ca name=\"the-solution\" href=\"#the-solution\"\u003E\n  \u003C\u002Fa\u003E\n  The Solution\n\u003C\u002Fh1\u003E\n\n\u003Ch2\u003E\n  \u003Ca name=\"domain-driven-design\" href=\"#domain-driven-design\"\u003E\n  \u003C\u002Fa\u003E\n  Domain Driven Design\n\u003C\u002Fh2\u003E\n\n\u003Cp\u003EThe first step was to identify the different domains represented within the larger DAG. From the outside, these may seem simple. The core services can be easy to identify but the boundaries are harder to identify. Where does one domain end and another begin? Our criteria for each domain was resolved around which team supported the service called. In addition, it was agreed the upstream domain was responsible for publishing an event when a material step in the DAG had completed. The downstream domain was responsible to consume that event. Using these guidelines, we were able to split the DAG out into 3 separate domains.\u003C\u002Fp\u003E\n\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--bkuUKRPT--\u002Fc_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Farticles\u002F76e2s6gtmh7xlypd6xs4.png\" class=\"article-body-image-wrapper\"\u003E\u003Cimg src=\"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--bkuUKRPT--\u002Fc_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Farticles\u002F76e2s6gtmh7xlypd6xs4.png\" alt=\"Alt Text\" loading=\"lazy\"\u003E\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\n\u003Ch2\u003E\n  \u003Ca name=\"communication-between-domains\" href=\"#communication-between-domains\"\u003E\n  \u003C\u002Fa\u003E\n  Communication between domains\n\u003C\u002Fh2\u003E\n\n\u003Cp\u003EWe knew we needed to communicate between domains. This communication would involve more than just a marker to say that an event had happened. We also needed to pass some parameters between domains. These parameters were necessary to the execution of the end-to-end flow and needed to be passed from domain to domain. \u003C\u002Fp\u003E\n\n\u003Cp\u003EThe term event-driven has become ubiquitous in modern software development but what does it mean? What exactly is an event? According to AWS\u003C\u002Fp\u003E\n\n\u003Cblockquote\u003E\n\u003Cp\u003EAn event is a change in state, or an update, like an item being placed in a shopping cart on an e-commerce website. Events can either carry the state (the item purchased, its price, and a delivery address) or events can be identifiers (a notification that an order was shipped).\u003C\u002Fp\u003E\n\u003C\u002Fblockquote\u003E\n\n\u003Cp\u003EUsing this definition, we would able to use the event to pass information from one domain to another. \u003C\u002Fp\u003E\n\n\u003Ch2\u003E\n  \u003Ca name=\"technical-solution\" href=\"#technical-solution\"\u003E\n  \u003C\u002Fa\u003E\n  Technical solution\n\u003C\u002Fh2\u003E\n\n\u003Cp\u003EWhile our Airflow clusters are hosted on-premise, we decided early on that we wanted to use AWS services to publish and subscribe to events. We have an internal goal to host our services on AWS and to use a serverless service where we can. Ultimately, the SNS Fanout to SQS pattern fitted well to our requirements. For more information on this pattern, see this post on the AWS blog.\u003C\u002Fp\u003E\n\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Faws.amazon.com\u002Fblogs\u002Fcompute\u002Fenriching-event-driven-architectures-with-aws-event-fork-pipelines\u002F\"\u003Ehttps:\u002F\u002Faws.amazon.com\u002Fblogs\u002Fcompute\u002Fenriching-event-driven-architectures-with-aws-event-fork-pipelines\u002F\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\n\u003Cp\u003EThis pattern allows us to separate out the publisher and subscriber into distinct services. The upstream service publishes an SNS topic with the event details. Each downstream service owns a separate SQS queue that subscribes to that topic. A JSON document can be passed between both services to communicate any necessary parameters.\u003C\u002Fp\u003E\n\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--Cz-3HJGa--\u002Fc_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Farticles\u002F86o179nxa2ywdxa1umxb.png\" class=\"article-body-image-wrapper\"\u003E\u003Cimg src=\"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--Cz-3HJGa--\u002Fc_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Farticles\u002F86o179nxa2ywdxa1umxb.png\" alt=\"Alt Text\" loading=\"lazy\"\u003E\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\n\u003Cp\u003E1) This is the upstream Airflow DAG. Once it has passed a certain point, a JSON document is passed via API Gateway to an SNS topic. \u003Cbr\u003E\n2) SNS immediately informs all subscribers that a new event has been received. The JSON document is passed along to all subscribers.\u003Cbr\u003E\n3) In the downstream domain, an FIFO SQS queue is subscribed to the SNS topic. \u003Cbr\u003E\n4) The first step in the downstream DAG polls the SQS queue on a regular interval for messages using API Gateway. If a message is on the queue, the step validates the message to see if it is properly formed. If so, it kicks off the DAG with the parameters from the JSON document and deletes the message from the queue via API Gateway.\u003C\u002Fp\u003E\n\n\u003Cp\u003EAn obvious advantage of this design is that when multiple SQS queues can subscribe to the SNS topic without impacting on the upstream DAG or other subscribed SQS queues.\u003C\u002Fp\u003E\n\n\u003Cp\u003ENote: No Lambdas were harmed in the development of this application. Serverless is about more than Lambda.\u003C\u002Fp\u003E\n\n\u003Ch2\u003E\n  \u003Ca name=\"cdk\" href=\"#cdk\"\u003E\n  \u003C\u002Fa\u003E\n  CDK\n\u003C\u002Fh2\u003E\n\n\u003Cp\u003EWe used CDK to deploy our services. This construct is very similar to what we used. \u003C\u002Fp\u003E\n\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fconstructs.dev\u002Fpackages\u002F@aws-solutions-constructs\u002Faws-sns-sqs\u002Fv\u002F1.120.0?lang=python\"\u003Ehttps:\u002F\u002Fconstructs.dev\u002Fpackages\u002F@aws-solutions-constructs\u002Faws-sns-sqs\u002Fv\u002F1.120.0?lang=python\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\n\u003Cp\u003EHowever, you will need to split out the SQS queue into the downstream domains code base parameterized with the name of the SNS topic. This is still a manual step for us but we are investigating the use of AWS Systems Manager Parameter Store to store and retrieve the name of relevant topic within the CI\u002FCD process.\u003C\u002Fp\u003E\n\n\u003Ch1\u003E\n  \u003Ca name=\"summary\" href=\"#summary\"\u003E\n  \u003C\u002Fa\u003E\n  Summary\n\u003C\u002Fh1\u003E\n\n\u003Cp\u003EUtilizing AWS services to facilitate an event-driven architecture  has been a game-changer for us. It is a relatively simple change in our case but provides several powerful benefits.\u003C\u002Fp\u003E\n\n\u003Cp\u003ETo find out more about how AWS can help you decouple your applications and take advantage of event driven architectures, check out this link:\u003C\u002Fp\u003E\n\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Faws.amazon.com\u002Fevent-driven-architecture\u002F\"\u003Ehttps:\u002F\u002Faws.amazon.com\u002Fevent-driven-architecture\u002F\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\n\u003Cp\u003ETo check out the individual services used, use the links below:\u003C\u002Fp\u003E\n\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Faws.amazon.com\u002Fsqs\u002F\"\u003Ehttps:\u002F\u002Faws.amazon.com\u002Fsqs\u002F\u003C\u002Fa\u003E\u003Cbr\u003E\n\u003Ca href=\"https:\u002F\u002Faws.amazon.com\u002Fsns\u002F\"\u003Ehttps:\u002F\u002Faws.amazon.com\u002Fsns\u002F\u003C\u002Fa\u003E\u003Cbr\u003E\n\u003Ca href=\"https:\u002F\u002Faws.amazon.com\u002Fapi-gateway\u002F\"\u003Ehttps:\u002F\u002Faws.amazon.com\u002Fapi-gateway\u002F\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\n",body_markdown:"#Introduction\nApplying domain-driven design and an event-driven architecture to the orchestration of our services has given our teams some very practical benefits in their day-to-day work on development and support. \n\n#The Problem\nUp until recently, we ran our main scoring job in one big DAG running in Airflow. This DAG calls services developed and maintained by at least 3 separate teams. With this setup, we were tightly coupling our systems, our processes (on-call, support) and our development and technology choices.\n\n![Alt Text](https:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Farticles\u002Fds0z3wyluo28u83p0tp6.png)\n\nIn practice, here are a couple of real world problems we were running into:\n\n1) The upstream team had several variations of their steps within the DAG. Each variation needed to have our teams steps copied and maintained in separate DAGs. Decoupling allows us to keep all our steps in a single DAG and to know where exactly our services are being orchestrated from.\n2) The decision to use Airflow was made by the upstream team as it made sense for their skills and technologies. Decoupling will also allow us to use a technology that may be better suited to our teams skills and technologies. For example, we could move to Step Functions if we wanted. We will not be bound to another team or domains technology choices.\n3) In addition to being on a mailing list for all alerts from the DAG, having to troubleshoot any failure may involve going through the larger DAG. While this may seem minor, situations like these can take a toll on a developer's productivity. Having our own separate DAG allows us to focus on our own services.\n\n#The Solution\n##Domain Driven Design\nThe first step was to identify the different domains represented within the larger DAG. From the outside, these may seem simple. The core services can be easy to identify but the boundaries are harder to identify. Where does one domain end and another begin? Our criteria for each domain was resolved around which team supported the service called. In addition, it was agreed the upstream domain was responsible for publishing an event when a material step in the DAG had completed. The downstream domain was responsible to consume that event. Using these guidelines, we were able to split the DAG out into 3 separate domains.\n\n![Alt Text](https:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Farticles\u002F76e2s6gtmh7xlypd6xs4.png)\n\n##Communication between domains\nWe knew we needed to communicate between domains. This communication would involve more than just a marker to say that an event had happened. We also needed to pass some parameters between domains. These parameters were necessary to the execution of the end-to-end flow and needed to be passed from domain to domain. \n\nThe term event-driven has become ubiquitous in modern software development but what does it mean? What exactly is an event? According to AWS\n\n\u003E An event is a change in state, or an update, like an item being placed in a shopping cart on an e-commerce website. Events can either carry the state (the item purchased, its price, and a delivery address) or events can be identifiers (a notification that an order was shipped).\n\nUsing this definition, we would able to use the event to pass information from one domain to another. \n\n##Technical solution\nWhile our Airflow clusters are hosted on-premise, we decided early on that we wanted to use AWS services to publish and subscribe to events. We have an internal goal to host our services on AWS and to use a serverless service where we can. Ultimately, the SNS Fanout to SQS pattern fitted well to our requirements. For more information on this pattern, see this post on the AWS blog.\n\nhttps:\u002F\u002Faws.amazon.com\u002Fblogs\u002Fcompute\u002Fenriching-event-driven-architectures-with-aws-event-fork-pipelines\u002F\n\nThis pattern allows us to separate out the publisher and subscriber into distinct services. The upstream service publishes an SNS topic with the event details. Each downstream service owns a separate SQS queue that subscribes to that topic. A JSON document can be passed between both services to communicate any necessary parameters.\n\n![Alt Text](https:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Farticles\u002F86o179nxa2ywdxa1umxb.png)\n\n1) This is the upstream Airflow DAG. Once it has passed a certain point, a JSON document is passed via API Gateway to an SNS topic. \n2) SNS immediately informs all subscribers that a new event has been received. The JSON document is passed along to all subscribers.\n3) In the downstream domain, an FIFO SQS queue is subscribed to the SNS topic. \n4) The first step in the downstream DAG polls the SQS queue on a regular interval for messages using API Gateway. If a message is on the queue, the step validates the message to see if it is properly formed. If so, it kicks off the DAG with the parameters from the JSON document and deletes the message from the queue via API Gateway.\n\nAn obvious advantage of this design is that when multiple SQS queues can subscribe to the SNS topic without impacting on the upstream DAG or other subscribed SQS queues.\n\nNote: No Lambdas were harmed in the development of this application. Serverless is about more than Lambda.\n\n##CDK \nWe used CDK to deploy our services. This construct is very similar to what we used. \n\nhttps:\u002F\u002Fconstructs.dev\u002Fpackages\u002F@aws-solutions-constructs\u002Faws-sns-sqs\u002Fv\u002F1.120.0?lang=python\n\nHowever, you will need to split out the SQS queue into the downstream domains code base parameterized with the name of the SNS topic. This is still a manual step for us but we are investigating the use of AWS Systems Manager Parameter Store to store and retrieve the name of relevant topic within the CI\u002FCD process.\n\n#Summary\nUtilizing AWS services to facilitate an event-driven architecture  has been a game-changer for us. It is a relatively simple change in our case but provides several powerful benefits.\n\nTo find out more about how AWS can help you decouple your applications and take advantage of event driven architectures, check out this link:\n\nhttps:\u002F\u002Faws.amazon.com\u002Fevent-driven-architecture\u002F\n\nTo check out the individual services used, use the links below:\n\nhttps:\u002F\u002Faws.amazon.com\u002Fsqs\u002F\nhttps:\u002F\u002Faws.amazon.com\u002Fsns\u002F\nhttps:\u002F\u002Faws.amazon.com\u002Fapi-gateway\u002F",user:{name:"Tom Milner",username:e,twitter_username:e,github_username:"thomasmilner",website_url:a,profile_image:"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--XwglO3zm--\u002Fc_fill,f_auto,fl_progressive,h_640,q_auto,w_640\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Fuser\u002Fprofile_image\u002F311858\u002F74d52a71-2385-4409-84c5-9becea50a557.jpg",profile_image_90:"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--31nWgRnT--\u002Fc_fill,f_auto,fl_progressive,h_90,q_auto,w_90\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Fuser\u002Fprofile_image\u002F311858\u002F74d52a71-2385-4409-84c5-9becea50a557.jpg"},organization:{name:"AWS Community Builders ",username:f,slug:f,profile_image:"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--zmOZQNzv--\u002Fc_fill,f_auto,fl_progressive,h_640,q_auto,w_640\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Forganization\u002Fprofile_image\u002F2794\u002F88da75b6-aadd-4ea1-8083-ae2dfca8be94.png",profile_image_90:"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--vWmcJ-ty--\u002Fc_fill,f_auto,fl_progressive,h_90,q_auto,w_90\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Forganization\u002Fprofile_image\u002F2794\u002F88da75b6-aadd-4ea1-8083-ae2dfca8be94.png"}}},serverRendered:true,routePath:"\u002Farticles\u002Ftom_millner\u002F821876",config:{_app:{basePath:"\u002F",assetsPath:"\u002F_nuxt\u002F",cdnURL:a}}}}(null,"2021-09-13T20:08:39Z","https:\u002F\u002Fdev.to\u002Faws-builders\u002Fdecouple-your-dags-with-an-event-driven-architecture-on-aws-bk",25,"tom_millner","aws-builders"));