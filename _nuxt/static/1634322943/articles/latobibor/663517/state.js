window.__NUXT__=(function(a,b,c,d,e,f){return {staticAssetsBase:"\u002F_nuxt\u002Fstatic\u002F1634322943",layout:"default",error:a,state:{currentArticle:{type_of:"article",id:663517,title:"Tech stories: completely wrong data ignored",description:"Reading how a serious problem about fake networks got ignored at Facebook I remembered my own little...",readable_publish_date:"Apr 12",slug:"tech-stories-completely-wrong-data-ignored-5pc",path:"\u002Flatobibor\u002Ftech-stories-completely-wrong-data-ignored-5pc",url:c,comments_count:0,public_reactions_count:d,collection_id:a,published_timestamp:b,positive_reactions_count:d,cover_image:"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--U6d22sBm--\u002Fc_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Farticles\u002Ftpxp7gkm5jzba8dho3rg.jpeg",social_image:"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--KnHMT80G--\u002Fc_imagga_scale,f_auto,fl_progressive,h_500,q_auto,w_1000\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Farticles\u002Ftpxp7gkm5jzba8dho3rg.jpeg",canonical_url:c,created_at:b,edited_at:"2021-04-12T20:31:51Z",crossposted_at:a,published_at:b,last_comment_at:b,reading_time_minutes:3,tag_list:"watercooler, devlife, productmanagement",tags:[e,"devlife","productmanagement"],body_html:"\u003Cp\u003EReading how a serious problem about \u003Ca href=\"https:\u002F\u002Fwww.theguardian.com\u002Ftechnology\u002F2021\u002Fapr\u002F12\u002Ffacebook-fake-engagement-whistleblower-sophie-zhang\"\u003Efake networks got ignored at Facebook\u003C\u002Fa\u003E I remembered my own little story about raising a problem and getting the hammer for it. This was also partly the reason I think I was fired: \u003Cem\u003E\"AndrÃ¡s, why are you spending time on this when you need to...\"\u003C\u002Fem\u003E.\u003C\u002Fp\u003E\n\n\u003Ch2\u003E\n  \u003Ca name=\"the-chilling-feeling-of-discovering-wrong-data\" href=\"#the-chilling-feeling-of-discovering-wrong-data\"\u003E\n  \u003C\u002Fa\u003E\n  The chilling feeling of discovering wrong data\n\u003C\u002Fh2\u003E\n\n\u003Cp\u003EThe company I was working for wanted to employ a hybrid strategy of collecting \u003Ccode\u003Equantitative\u003C\u002Fcode\u003E (registering \"clicks\" and user behavior and then crunch the numbers) and \u003Ccode\u003Equalitative\u003C\u002Fcode\u003E (observing user behavior through interviews). This was an excellent approach but it depended on the quality of the data collected.\u003C\u002Fp\u003E\n\n\u003Cp\u003EI was sitting at my desk when one of the team leads and our UX researcher were chatting about some data they used to draw decisions upon.\u003C\u002Fp\u003E\n\n\u003Cp\u003EThe assumption they had was that\u003C\u002Fp\u003E\n\n\u003Cblockquote\u003E\n\u003Cp\u003E90% of the users reading help articles are not logged in.\u003C\u002Fp\u003E\n\u003C\u002Fblockquote\u003E\n\n\u003Cp\u003EThis was drawn from user behavior data. The data consisted of events: \u003Ccode\u003EUser X clicked Button Y and user X has these properties {...}\u003C\u002Fcode\u003E. \u003Cbr\u003E\nMany teams were adding their own events to this.\u003C\u002Fp\u003E\n\n\u003Cp\u003EI was pretty surprised to hear this number so I turned to my right and asked \u003Cbr\u003E\n\u003Cem\u003E\"What event property did you use to determine this?\"\u003C\u002Fem\u003E \u003C\u002Fp\u003E\n\n\u003Cp\u003EThey replied with a particular property (\u003Ccode\u003Eregistered\u003C\u002Fcode\u003E??? I can't recall the name, it's not important).\u003C\u002Fp\u003E\n\n\u003Cp\u003EFrom my previous endeavours I knew already that \u003Cem\u003Ethat\u003C\u002Fem\u003E particular property was not really trustworthy. In fact I never understood how it worked (until I have investigated it; and then I shook my head...).\u003C\u002Fp\u003E\n\n\u003Cp\u003EI freaked out and started investigating how that property is set. It turned out that they heard of somebody who said that this is the right property.\u003C\u002Fp\u003E\n\n\u003Cp\u003EBut it wasn't. In fact there were about \u003Cstrong\u003E3 properties\u003C\u002Fstrong\u003E and none of them was actually telling if the user was logged in or not (but we fixed it by adding a fourth, which was accurate ðŸ¤«).\u003C\u002Fp\u003E\n\n\u003Ch2\u003E\n  \u003Ca name=\"bad-data-cool-story-bro\" href=\"#bad-data-cool-story-bro\"\u003E\n  \u003C\u002Fa\u003E\n  Bad data? Cool story bro!\n\u003C\u002Fh2\u003E\n\n\u003Cp\u003EBy stopping my work and franticly trying to investigate how those properties are \u003Cem\u003Eactually\u003C\u002Fem\u003E working I realized the real number was around 50% or more: most people were logged in. We can't base our strategy on the totally false 90% value.\u003C\u002Fp\u003E\n\n\u003Cp\u003EAnd then what happened? \u003Cstrong\u003ENothing!\u003C\u002Fstrong\u003E ðŸ™ƒ\u003C\u002Fp\u003E\n\n\u003Cp\u003EThey did not really give a f--- about it, and I was even scolded for setting my work aside for a couple of days.\u003C\u002Fp\u003E\n\n\u003Cblockquote\u003E\n\u003Cp\u003ECool story bro! Now go and do work.\u003C\u002Fp\u003E\n\u003C\u002Fblockquote\u003E\n\n\u003Cp\u003EI was shocked by this. In my spare time I was going down the rabbit hole and I realized we collect data in many ways so flawed that it can't be trusted. Partly from having so many independent teams and partly because no one likes to change plans. \u003C\u002Fp\u003E\n\n\u003Cblockquote\u003E\n\u003Cp\u003EThe decision was made and annoying facts should not bother it.\u003C\u002Fp\u003E\n\u003C\u002Fblockquote\u003E\n\n\u003Cp\u003EI wrote a big plan about what to do and I could actually warn one of the data scientists we had. And that's it.\u003C\u002Fp\u003E\n\n\u003Cp\u003EA bit later I was fired for \u003Cem\u003E\"not being a good cultural fit\"\u003C\u002Fem\u003E. Obviously there were more stories behind it, so stay tuned ðŸ˜„.\u003C\u002Fp\u003E\n\n\u003Cp\u003EAnd now the constructive part...\u003C\u002Fp\u003E\n\n\u003Ch2\u003E\n  \u003Ca name=\"how-to-fix-serious-data-collection-flaw\" href=\"#how-to-fix-serious-data-collection-flaw\"\u003E\n  \u003C\u002Fa\u003E\n  How to fix \"serious data collection flaw\"\n\u003C\u002Fh2\u003E\n\n\u003Cp\u003EThere are many aspects here.\u003C\u002Fp\u003E\n\n\u003Ch3\u003E\n  \u003Ca name=\"clean-code-clean-events\" href=\"#clean-code-clean-events\"\u003E\n  \u003C\u002Fa\u003E\n  Clean code, clean events\n\u003C\u002Fh3\u003E\n\n\u003Cp\u003EMost importantly, events need to be clean and clear. The names should be meaningful and they should be regularly checked for  validity. If you have multiple teams you can still have some core data analysts who have the responsibility of improving the quality of most important areas.\u003C\u002Fp\u003E\n\n\u003Ch3\u003E\n  \u003Ca name=\"shit-data-shit-decision-gt-fix-data-and-decision\" href=\"#shit-data-shit-decision-gt-fix-data-and-decision\"\u003E\n  \u003C\u002Fa\u003E\n  Shit data, shit decision =&gt; fix data \u003Cem\u003Eand\u003C\u002Fem\u003E decision\n\u003C\u002Fh3\u003E\n\n\u003Cp\u003EIt sucks to stop your work. But if you uncover this huge flaw you have to take it seriously. The entire team should take it seriously. Or at least the team lead or product manager.\u003C\u002Fp\u003E\n\n\u003Ch3\u003E\n  \u003Ca name=\"anticipate-the-disruption\" href=\"#anticipate-the-disruption\"\u003E\n  \u003C\u002Fa\u003E\n  Anticipate the disruption\n\u003C\u002Fh3\u003E\n\n\u003Cp\u003ENormalcy bias is at play here as well: \u003Cem\u003E\"You just said that my assumptions were completely wrong, but I pretend it's no big deal and keep the dear assumptions.\"\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\n\u003Cp\u003EIf you expect that you will have disruptions, your sense of normalcy will incorporate that you need to work unexpectedly on major flaws.\u003C\u002Fp\u003E\n\n\u003Ch3\u003E\n  \u003Ca name=\"if-politics-is-more-important-than-accurate-decisions-you-have-a-cultural-problem\" href=\"#if-politics-is-more-important-than-accurate-decisions-you-have-a-cultural-problem\"\u003E\n  \u003C\u002Fa\u003E\n  If politics is more important than accurate decisions, you have a cultural problem\n\u003C\u002Fh3\u003E\n\n\u003Cp\u003EThere I have said it. You have to have ear and respect for the engineers, data scientists and low-key workers raising serious issues. Pretending the problems do not exist will cost you real \u003Ccode\u003E$$$\u003C\u002Fcode\u003Es (and also demoralises your workforce). Even worse strategy to expect them to solve the problems in their spare time, since people will do uncoordinated guerrilla actions, leading to an even more confusing system.\u003C\u002Fp\u003E\n\n\u003Cp\u003EThe mistreated issues will mount up eventually and you are going to shoot yourself in the foot. At least there's free cereal in the office kitchen and there are important motivational messages scattered on the walls.\u003C\u002Fp\u003E\n\n",body_markdown:"Reading how a serious problem about [fake networks got ignored at Facebook](https:\u002F\u002Fwww.theguardian.com\u002Ftechnology\u002F2021\u002Fapr\u002F12\u002Ffacebook-fake-engagement-whistleblower-sophie-zhang) I remembered my own little story about raising a problem and getting the hammer for it. This was also partly the reason I think I was fired: _\"AndrÃ¡s, why are you spending time on this when you need to...\"_.\n\n## The chilling feeling of discovering wrong data\nThe company I was working for wanted to employ a hybrid strategy of collecting `quantitative` (registering \"clicks\" and user behavior and then crunch the numbers) and `qualitative` (observing user behavior through interviews). This was an excellent approach but it depended on the quality of the data collected.\n\nI was sitting at my desk when one of the team leads and our UX researcher were chatting about some data they used to draw decisions upon.\n\nThe assumption they had was that\n\n\u003E 90% of the users reading help articles are not logged in.\n\nThis was drawn from user behavior data. The data consisted of events: `User X clicked Button Y and user X has these properties {...}`. \nMany teams were adding their own events to this.\n\nI was pretty surprised to hear this number so I turned to my right and asked \n_\"What event property did you use to determine this?\"_ \n\nThey replied with a particular property (`registered`??? I can't recall the name, it's not important).\n\nFrom my previous endeavours I knew already that _that_ particular property was not really trustworthy. In fact I never understood how it worked (until I have investigated it; and then I shook my head...).\n\nI freaked out and started investigating how that property is set. It turned out that they heard of somebody who said that this is the right property.\n\nBut it wasn't. In fact there were about **3 properties** and none of them was actually telling if the user was logged in or not (but we fixed it by adding a fourth, which was accurate ðŸ¤«).\n\n## Bad data? Cool story bro!\nBy stopping my work and franticly trying to investigate how those properties are _actually_ working I realized the real number was around 50% or more: most people were logged in. We can't base our strategy on the totally false 90% value.\n\nAnd then what happened? **Nothing!** ðŸ™ƒ\n\nThey did not really give a f--- about it, and I was even scolded for setting my work aside for a couple of days.\n\n\u003E Cool story bro! Now go and do work.\n\nI was shocked by this. In my spare time I was going down the rabbit hole and I realized we collect data in many ways so flawed that it can't be trusted. Partly from having so many independent teams and partly because no one likes to change plans. \n\n\u003E The decision was made and annoying facts should not bother it.\n\nI wrote a big plan about what to do and I could actually warn one of the data scientists we had. And that's it.\n\nA bit later I was fired for _\"not being a good cultural fit\"_. Obviously there were more stories behind it, so stay tuned ðŸ˜„.\n\nAnd now the constructive part...\n\n## How to fix \"serious data collection flaw\"\nThere are many aspects here.\n\n### Clean code, clean events\nMost importantly, events need to be clean and clear. The names should be meaningful and they should be regularly checked for  validity. If you have multiple teams you can still have some core data analysts who have the responsibility of improving the quality of most important areas.\n\n### Shit data, shit decision =\u003E fix data _and_ decision\nIt sucks to stop your work. But if you uncover this huge flaw you have to take it seriously. The entire team should take it seriously. Or at least the team lead or product manager.\n\n### Anticipate the disruption\nNormalcy bias is at play here as well: _\"You just said that my assumptions were completely wrong, but I pretend it's no big deal and keep the dear assumptions.\"_\n\nIf you expect that you will have disruptions, your sense of normalcy will incorporate that you need to work unexpectedly on major flaws.\n\n### If politics is more important than accurate decisions, you have a cultural problem\nThere I have said it. You have to have ear and respect for the engineers, data scientists and low-key workers raising serious issues. Pretending the problems do not exist will cost you real `$$$`s (and also demoralises your workforce). Even worse strategy to expect them to solve the problems in their spare time, since people will do uncoordinated guerrilla actions, leading to an even more confusing system.\n\nThe mistreated issues will mount up eventually and you are going to shoot yourself in the foot. At least there's free cereal in the office kitchen and there are important motivational messages scattered on the walls.",user:{name:"AndrÃ¡s TÃ³th",username:f,twitter_username:a,github_username:f,website_url:a,profile_image:"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--NGz2QbVa--\u002Fc_fill,f_auto,fl_progressive,h_640,q_auto,w_640\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Fuser\u002Fprofile_image\u002F368510\u002F0e824261-6d1a-471b-8cc1-87f40e18f34e.jpeg",profile_image_90:"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--IW62YYv---\u002Fc_fill,f_auto,fl_progressive,h_90,q_auto,w_90\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Fuser\u002Fprofile_image\u002F368510\u002F0e824261-6d1a-471b-8cc1-87f40e18f34e.jpeg"},flare_tag:{name:e,bg_color_hex:"#D0ECFF",text_color_hex:"#130074"}}},serverRendered:true,routePath:"\u002Farticles\u002Flatobibor\u002F663517",config:{_app:{basePath:"\u002F",assetsPath:"\u002F_nuxt\u002F",cdnURL:a}}}}(null,"2021-04-12T19:56:53Z","https:\u002F\u002Fdev.to\u002Flatobibor\u002Ftech-stories-completely-wrong-data-ignored-5pc",1,"watercooler","latobibor"));