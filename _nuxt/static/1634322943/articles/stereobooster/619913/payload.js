__NUXT_JSONP__("/articles/stereobooster/619913", (function(a,b,c,d,e,f){c.type_of="article";c.id=619913;c.title="Parsing with derivatives";c.description="Based on:    Theory of Computation (CS3102), Spring 2017, videos are here   It’s Time for a New Old L...";c.readable_publish_date="Feb 27";c.slug="parsing-with-derivatives-5dhn";c.path="\u002Fstereobooster\u002Fparsing-with-derivatives-5dhn";c.url="https:\u002F\u002Fdev.to\u002Fstereobooster\u002Fparsing-with-derivatives-5dhn";c.comments_count=0;c.public_reactions_count=d;c.collection_id=b;c.published_timestamp=e;c.positive_reactions_count=d;c.cover_image=b;c.social_image="https:\u002F\u002Fdev.to\u002Fsocial_previews\u002Farticle\u002F619913.png";c.canonical_url="https:\u002F\u002Fstereobooster.com\u002Fposts\u002Fparsing-with-derivatives\u002F";c.created_at="2021-02-27T12:34:09Z";c.edited_at=b;c.crossposted_at=e;c.published_at=f;c.last_comment_at=f;c.reading_time_minutes=7;c.tag_list="computerscience, syntax, grammar, parser";c.tags=["computerscience","syntax","grammar","parser"];c.body_html="\u003Cp\u003EBased on:\u003C\u002Fp\u003E\n\n\u003Cul\u003E\n\u003Cli\u003E\n\u003Ca href=\"http:\u002F\u002Fwww.cs.virginia.edu\u002F~robins\u002Fcs3102\u002Fslides\u002FTheory_Slides_Formal_Languages_and_Machines_v52.pdf\"\u003ETheory of Computation (CS3102), Spring 2017\u003C\u002Fa\u003E, videos are \u003Ca href=\"http:\u002F\u002Fwww.cs.virginia.edu\u002F~robins\u002Fvideos.html\"\u003Ehere\u003C\u002Fa\u003E\n\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Ca href=\"https:\u002F\u002Fgroups.csail.mit.edu\u002Fmac\u002Fusers\u002Fgjs\u002F6.945\u002Freadings\u002FSteele-MIT-April-2017.pdf\"\u003EIt’s Time for a New Old Language, 2017\u003C\u002Fa\u003E, \u003Ca href=\"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=dCuZkaaou0Q\"\u003Etalk\u003C\u002Fa\u003E by Guy L. Steele Jr.\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Ca href=\"http:\u002F\u002Fmatt.might.net\u002Fpapers\u002Fmight2011derivatives.pdf\"\u003EParsing with Derivatives, 2011\u003C\u002Fa\u003E by Matthew Might, David Darais, Daniel Spiewak, \u003Ca href=\"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=ZzsK8Am6dKU\"\u003Evideo\u003C\u002Fa\u003E.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\n\u003Ch2\u003E\n  \u003Ca name=\"history-of-notation\" href=\"#history-of-notation\" class=\"anchor\"\u003E\n  \u003C\u002Fa\u003E\n  History of notation\n\u003C\u002Fh2\u003E\n\n\u003Cp\u003EAll material I have read on the subject use slightly different notation. Apparently, there is some history behind it.\u003C\u002Fp\u003E\n\n\u003Cp\u003ESlide 21 from Guy L. Steele Jr. presentation:\u003C\u002Fp\u003E\n\n\u003Cul\u003E\n\u003Cli\u003E\n\u003Cstrong\u003E1951\u003C\u002Fstrong\u003E Stephen Kleene develops regular expressions to describe McCulloch-Pitts (1943) nerve nets (uses \u003Ccode\u003E∨\u003C\u002Fcode\u003E for choice; considers postfix \u003Ccode\u003E∗\u003C\u002Fcode\u003E, but decides to make it a binary operator to avoid having empty strings: \u003Ccode\u003Ex∗y\u003C\u002Fcode\u003E means any number of copies of \u003Ccode\u003Ex\u003C\u002Fcode\u003E, followed by \u003Ccode\u003Ey\u003C\u002Fcode\u003E).\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Cstrong\u003E1956\u003C\u002Fstrong\u003E Journal publication of Kleene’s technical report: binary \u003Ccode\u003E∗\u003C\u002Fcode\u003E only.\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Cstrong\u003E1958\u003C\u002Fstrong\u003E Copi, Elgot, and Wright formulate REs using \u003Ccode\u003E·\u003C\u002Fcode\u003E and \u003Ccode\u003E∨\u003C\u002Fcode\u003E and postfix \u003Ccode\u003E∗\u003C\u002Fcode\u003E.\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Cstrong\u003E1962\u003C\u002Fstrong\u003E Janusz Brzozowki uses binary \u003Ccode\u003E+\u003C\u002Fcode\u003E for \u003Ccode\u003E∨\u003C\u002Fcode\u003E and introduces postfix \u003Ccode\u003E+\u003C\u002Fcode\u003E.\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Cstrong\u003E1968\u003C\u002Fstrong\u003E Ken Thompson’s paper “Regular Expression Search Algorithm” uses \u003Ccode\u003E|\u003C\u002Fcode\u003E.\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Cstrong\u003E1973\u003C\u002Fstrong\u003E Thompson creates \u003Ccode\u003Egrep\u003C\u002Fcode\u003E from \u003Ccode\u003Eed\u003C\u002Fcode\u003E editor for use by Doug McIlroy.\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Cstrong\u003E1975\u003C\u002Fstrong\u003E Alfred Aho creates \u003Ccode\u003Eegrep\u003C\u002Fcode\u003E (includes \u003Ccode\u003E( )\u003C\u002Fcode\u003E, \u003Ccode\u003E|\u003C\u002Fcode\u003E, \u003Ccode\u003E*\u003C\u002Fcode\u003E, \u003Ccode\u003E+\u003C\u002Fcode\u003E, \u003Ccode\u003E?\u003C\u002Fcode\u003E).\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Cstrong\u003E1978\u003C\u002Fstrong\u003E CMU Alphard project uses regular expressions with \u003Ccode\u003E*\u003C\u002Fcode\u003E, \u003Ccode\u003E+\u003C\u002Fcode\u003E, and \u003Ccode\u003E#\u003C\u002Fcode\u003E.\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Cstrong\u003E1981\u003C\u002Fstrong\u003E CMU FEG and IDL use regular expressions with \u003Ccode\u003E*\u003C\u002Fcode\u003E, \u003Ccode\u003E+\u003C\u002Fcode\u003E, and \u003Ccode\u003E?\u003C\u002Fcode\u003E.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\n\u003Cp\u003EFor example, Robins (see \u003Ca href=\"https:\u002F\u002Fdev.to\u002Fstereobooster\u002Fnotes-on-parsing-theory-part-3-3248\"\u003Electure notes from the previous post\u003C\u002Fa\u003E) uses Brzozowki notation (\u003Ccode\u003E+\u003C\u002Fcode\u003E for union).\u003C\u002Fp\u003E\n\n\u003Cp\u003EMatthew Might (in Parsing with derivatives) uses a variation of Copi, Elgot, and Wright notation:\u003C\u002Fp\u003E\n\n\u003Cul\u003E\n\u003Cli\u003E\n\u003Ccode\u003E◦\u003C\u002Fcode\u003E instead of \u003Ccode\u003E·\u003C\u002Fcode\u003E\n\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Ccode\u003E∪\u003C\u002Fcode\u003E instead of \u003Ccode\u003E∨\u003C\u002Fcode\u003E\n\u003C\u002Fli\u003E\n\u003Cli\u003Euses \u003Ccode\u003Eϵ\u003C\u002Fcode\u003E - the same as Niklaus Wirth in “What can we do about the unnecessary diversity of notation for syntactic definitions?”\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\n\u003Cp\u003EAlmost everybody uses \u003Ccode\u003E*\u003C\u002Fcode\u003E the same way - postfix unary operator. The difference is that some notations use superscript and some use plain variation. To add more confusion: \u003Ccode\u003Eϵ\u003C\u002Fcode\u003E, \u003Ccode\u003Eε\u003C\u002Fcode\u003E are both the same Greek letter - epsilon - in different styles.\u003C\u002Fp\u003E\n\n\u003Cp\u003E\u003Cstrong\u003EHere supposed to be table, but dev.to can't handle tables correctly\u003C\u002Fstrong\u003E, so screenshot instead:\u003C\u002Fp\u003E\n\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--rr2CVk4---\u002Fc_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Farticles\u002F0mpktigfims1p97zd9e4.png\" class=\"article-body-image-wrapper\"\u003E\u003Cimg src=\"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--rr2CVk4---\u002Fc_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Farticles\u002F0mpktigfims1p97zd9e4.png\" alt=\"\" loading=\"lazy\"\u003E\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\n\u003Cp\u003E¹ approximation ² aka repetition ³ RE - regular expressions ⁴ \u003Ca href=\"http:\u002F\u002Fwww.pcre.org\u002Fcurrent\u002Fdoc\u002Fhtml\u002Fpcre2pattern.html#SEC1\"\u003EPCRE\u003C\u002Fa\u003E - Perl Compatible Regular Expressions\u003C\u002Fp\u003E\n\n\u003Ch2\u003E\n  \u003Ca name=\"dynamic-programming\" href=\"#dynamic-programming\" class=\"anchor\"\u003E\n  \u003C\u002Fa\u003E\n  Dynamic programming\n\u003C\u002Fh2\u003E\n\n\u003Cp\u003EIn the context of programming, it is an optimization technique developed by Richard Bellman in the 1950s. It can be applied to a specific class of recursive problems. For example, calculation of Fibonacci numbers or finding the shortest path in a graph.\u003C\u002Fp\u003E\n\n\u003Cp\u003EIn general, it allows to turn algorithms with exponential complexity to polynomial complexity (but may require more space). I won’t go into more details - but very primitively it boils down to memoization and cycle detection.\u003C\u002Fp\u003E\n\n\u003Cp\u003EYou can watch \u003Ca href=\"https:\u002F\u002Focw.mit.edu\u002Fcourses\u002Felectrical-engineering-and-computer-science\u002F6-006-introduction-to-algorithms-fall-2011\u002Flecture-videos\u002Flecture-19-dynamic-programming-i-fibonacci-shortest-paths\u002F\"\u003Ethis MIT course\u003C\u002Fa\u003E where it’s explained better.\u003C\u002Fp\u003E\n\n\u003Ch2\u003E\n  \u003Ca name=\"brzozowki-derivative\" href=\"#brzozowki-derivative\" class=\"anchor\"\u003E\n  \u003C\u002Fa\u003E\n  Brzozowki derivative\n\u003C\u002Fh2\u003E\n\n\u003Cp\u003EIn \u003Ca href=\"http:\u002F\u002Fkrchowdhary.com\u002Fme-tfl\u002F5-derivatives-of-regex-brzozowski.pdf\"\u003E1964 Brzozowki\u003C\u002Fa\u003E proposed idea of derivatives for regular expressions. Note: he uses \u003Ccode\u003Eλ\u003C\u002Fcode\u003E for \u003Ccode\u003Eϵ\u003C\u002Fcode\u003E and \u003Ccode\u003Eφ\u003C\u002Fcode\u003E for \u003Ccode\u003E∅\u003C\u002Fcode\u003E.\u003C\u002Fp\u003E\n\n\u003Cp\u003EFormally derivative defined as \u003Ccode\u003EDₐ(R) = { t | at ϵ R }\u003C\u002Fcode\u003E. Basically, it is the opposite of concatenation.\u003C\u002Fp\u003E\n\n\u003Cp\u003EFor example:\u003C\u002Fp\u003E\n\n\u003Cul\u003E\n\u003Cli\u003Eif we have language \u003Ccode\u003E{ abb, abc, bbb }\u003C\u002Fcode\u003E\n\u003C\u002Fli\u003E\n\u003Cli\u003Ederivative by \u003Ccode\u003Ea\u003C\u002Fcode\u003E will give \u003Ccode\u003E{ bb, bc }\u003C\u002Fcode\u003E\n\u003C\u002Fli\u003E\n\u003Cli\u003Ethen derivative by \u003Ccode\u003Eb\u003C\u002Fcode\u003E will give \u003Ccode\u003E{ b, c }\u003C\u002Fcode\u003E\n\u003C\u002Fli\u003E\n\u003Cli\u003Ethen derivative by \u003Ccode\u003Ec\u003C\u002Fcode\u003E will give \u003Ccode\u003E{ ε }\u003C\u002Fcode\u003E\n\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\n\u003Cp\u003EMore formally:\u003C\u002Fp\u003E\n\n\u003Cul\u003E\n\u003Cli\u003E\u003Ccode\u003EDₐa = ϵ\u003C\u002Fcode\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Ccode\u003EDₐb = ∅\u003C\u002Fcode\u003E\n\n\u003Cul\u003E\n\u003Cli\u003E\u003Ccode\u003EDₐϵ = ∅\u003C\u002Fcode\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Ccode\u003EDₐ∅ = ∅\u003C\u002Fcode\u003E\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\n\n\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Ccode\u003EDₐ(P*) = (DₐP)P*\u003C\u002Fcode\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Ccode\u003EDₐ(PQ) = (DₐP)Q + δ(P)DₐQ\u003C\u002Fcode\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Ccode\u003EDₐ(P+Q) = DₐP + DₐQ\u003C\u002Fcode\u003E\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\n\u003Cp\u003EBrzozowki shows how derivatives can be used to construct Mealy and Moore automata (finite state machines). Also, he shows how identity rules can be used to simplify automata.\u003C\u002Fp\u003E\n\n\u003Ch2\u003E\n  \u003Ca name=\"parser-combinators\" href=\"#parser-combinators\" class=\"anchor\"\u003E\n  \u003C\u002Fa\u003E\n  Parser combinators\n\u003C\u002Fh2\u003E\n\n\u003Cp\u003EIn \u003Ca href=\"https:\u002F\u002Frkrishnan.org\u002Ffiles\u002Fwadler-1985.pdf\"\u003E1985 Wadler\u003C\u002Fa\u003E proposed to represent parsers as functions and to construct bigger parsers by composing functions. The key idea is to start from parsers for atomic languages:\u003Cbr\u003E\n\u003C\u002Fp\u003E\n\n\u003Cdiv class=\"highlight js-code-highlight\"\u003E\n\u003Cpre class=\"highlight haskell\"\u003E\u003Ccode\u003E\u003Cspan class=\"c1\"\u003E-- empty language\u003C\u002Fspan\u003E\n\u003Cspan class=\"n\"\u003Efail\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Exs\u003C\u002Fspan\u003E       \u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E \u003Cspan class=\"kt\"\u003E[]\u003C\u002Fspan\u003E            \u003Cspan class=\"c1\"\u003E-- Dx(∅)   = ∅\u003C\u002Fspan\u003E\n\u003Cspan class=\"c1\"\u003E-- trivial language - empty string\u003C\u002Fspan\u003E\n\u003Cspan class=\"n\"\u003Eempty\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Ev\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Exs\u003C\u002Fspan\u003E    \u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E \u003Cspan class=\"p\"\u003E[(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Ev\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"n\"\u003Exs\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)]\u003C\u002Fspan\u003E     \u003Cspan class=\"c1\"\u003E-- Dϵ(P)   = P\u003C\u002Fspan\u003E\n\u003Cspan class=\"c1\"\u003E-- singleton language\u003C\u002Fspan\u003E\n\u003Cspan class=\"n\"\u003Elit\u003C\u002Fspan\u003E \u003Cspan class=\"sc\"\u003E'a'\u003C\u002Fspan\u003E \u003Cspan class=\"s\"\u003E\"abc\"\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E \u003Cspan class=\"p\"\u003E[(\u003C\u002Fspan\u003E\u003Cspan class=\"sc\"\u003E'a'\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"s\"\u003E\"bc\"\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)]\u003C\u002Fspan\u003E \u003Cspan class=\"c1\"\u003E-- Da(abc) = bc\u003C\u002Fspan\u003E\n\u003Cspan class=\"n\"\u003Elit\u003C\u002Fspan\u003E \u003Cspan class=\"sc\"\u003E'b'\u003C\u002Fspan\u003E \u003Cspan class=\"s\"\u003E\"abc\"\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E \u003Cspan class=\"kt\"\u003E[]\u003C\u002Fspan\u003E            \u003Cspan class=\"c1\"\u003E-- Db(abc) = ∅\u003C\u002Fspan\u003E\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Cdiv class=\"highlight__panel js-actions-panel\"\u003E\n\u003Cdiv class=\"highlight__panel-action js-fullscreen-code-action\"\u003E\n    \u003Csvg xmlns=\"http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg\" width=\"20px\" height=\"20px\" viewbox=\"0 0 24 24\" class=\"highlight-action crayons-icon highlight-action--fullscreen-on\"\u003E\u003Ctitle\u003EEnter fullscreen mode\u003C\u002Ftitle\u003E\n    \u003Cpath d=\"M16 3h6v6h-2V5h-4V3zM2 3h6v2H4v4H2V3zm18 16v-4h2v6h-6v-2h4zM4 19h4v2H2v-6h2v4z\"\u003E\u003C\u002Fpath\u003E\n\u003C\u002Fsvg\u003E\n\n    \u003Csvg xmlns=\"http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg\" width=\"20px\" height=\"20px\" viewbox=\"0 0 24 24\" class=\"highlight-action crayons-icon highlight-action--fullscreen-off\"\u003E\u003Ctitle\u003EExit fullscreen mode\u003C\u002Ftitle\u003E\n    \u003Cpath d=\"M18 7h4v2h-6V3h2v4zM8 9H2V7h4V3h2v6zm10 8v4h-2v-6h6v2h-4zM8 15v6H6v-4H2v-2h6z\"\u003E\u003C\u002Fpath\u003E\n\u003C\u002Fsvg\u003E\n\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E\n\n\n\n\u003Cp\u003EAtomic languages as finite state machines:\u003C\u002Fp\u003E\n\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--6TSXluw9--\u002Fc_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880\u002Fhttps:\u002F\u002Fstereobooster.com\u002Fposts\u002Fparsing-with-derivatives\u002F0.svg\" class=\"article-body-image-wrapper\"\u003E\u003Cimg src=\"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--6TSXluw9--\u002Fc_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880\u002Fhttps:\u002F\u002Fstereobooster.com\u002Fposts\u002Fparsing-with-derivatives\u002F0.svg\" alt=\"\" loading=\"lazy\"\u003E\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\n\u003Cp\u003EThen atomic parsers can be composed with union (\u003Ccode\u003Ealt\u003C\u002Fcode\u003E), concatenation (\u003Ccode\u003Eseq\u003C\u002Fcode\u003E), and Kleene star (\u003Ccode\u003Erep\u003C\u002Fcode\u003E) to create parsers for “bigger” languages.\u003C\u002Fp\u003E\n\n\u003Cp\u003EIt is a bit harder to see correspondence of derivatives to those parsers:\u003Cbr\u003E\n\u003C\u002Fp\u003E\n\n\u003Cdiv class=\"highlight js-code-highlight\"\u003E\n\u003Cpre class=\"highlight haskell\"\u003E\u003Ccode\u003E\u003Cspan class=\"n\"\u003Ealt\u003C\u002Fspan\u003E \u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Elit\u003C\u002Fspan\u003E \u003Cspan class=\"sc\"\u003E'a'\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)\u003C\u002Fspan\u003E \u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Elit\u003C\u002Fspan\u003E \u003Cspan class=\"sc\"\u003E'b'\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)\u003C\u002Fspan\u003E \u003Cspan class=\"s\"\u003E\"abc\"\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E \u003Cspan class=\"p\"\u003E[(\u003C\u002Fspan\u003E\u003Cspan class=\"sc\"\u003E'a'\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"s\"\u003E\"bc\"\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)]\u003C\u002Fspan\u003E\n\u003Cspan class=\"n\"\u003Eseq\u003C\u002Fspan\u003E \u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Elit\u003C\u002Fspan\u003E \u003Cspan class=\"sc\"\u003E'a'\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)\u003C\u002Fspan\u003E \u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Elit\u003C\u002Fspan\u003E \u003Cspan class=\"sc\"\u003E'b'\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)\u003C\u002Fspan\u003E \u003Cspan class=\"s\"\u003E\"abc\"\u003C\u002Fspan\u003E \u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E \u003Cspan class=\"p\"\u003E[(\u003C\u002Fspan\u003E\u003Cspan class=\"s\"\u003E\"ab\"\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"s\"\u003E\"c\"\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)]\u003C\u002Fspan\u003E\n\u003Cspan class=\"n\"\u003Erep\u003C\u002Fspan\u003E \u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"n\"\u003Elit\u003C\u002Fspan\u003E \u003Cspan class=\"sc\"\u003E'a'\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)\u003C\u002Fspan\u003E \u003Cspan class=\"s\"\u003E\"aac\"\u003C\u002Fspan\u003E           \u003Cspan class=\"o\"\u003E=\u003C\u002Fspan\u003E \u003Cspan class=\"p\"\u003E[(\u003C\u002Fspan\u003E\u003Cspan class=\"s\"\u003E\"aa\"\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"s\"\u003E\"c\"\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E),\u003C\u002Fspan\u003E \u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"s\"\u003E\"a\"\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"s\"\u003E\"ac\"\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E),\u003C\u002Fspan\u003E \u003Cspan class=\"p\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"s\"\u003E\"\"\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E,\u003C\u002Fspan\u003E \u003Cspan class=\"s\"\u003E\"aac\"\u003C\u002Fspan\u003E\u003Cspan class=\"p\"\u003E)]\u003C\u002Fspan\u003E\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Cdiv class=\"highlight__panel js-actions-panel\"\u003E\n\u003Cdiv class=\"highlight__panel-action js-fullscreen-code-action\"\u003E\n    \u003Csvg xmlns=\"http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg\" width=\"20px\" height=\"20px\" viewbox=\"0 0 24 24\" class=\"highlight-action crayons-icon highlight-action--fullscreen-on\"\u003E\u003Ctitle\u003EEnter fullscreen mode\u003C\u002Ftitle\u003E\n    \u003Cpath d=\"M16 3h6v6h-2V5h-4V3zM2 3h6v2H4v4H2V3zm18 16v-4h2v6h-6v-2h4zM4 19h4v2H2v-6h2v4z\"\u003E\u003C\u002Fpath\u003E\n\u003C\u002Fsvg\u003E\n\n    \u003Csvg xmlns=\"http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg\" width=\"20px\" height=\"20px\" viewbox=\"0 0 24 24\" class=\"highlight-action crayons-icon highlight-action--fullscreen-off\"\u003E\u003Ctitle\u003EExit fullscreen mode\u003C\u002Ftitle\u003E\n    \u003Cpath d=\"M18 7h4v2h-6V3h2v4zM8 9H2V7h4V3h2v6zm10 8v4h-2v-6h6v2h-4zM8 15v6H6v-4H2v-2h6z\"\u003E\u003C\u002Fpath\u003E\n\u003C\u002Fsvg\u003E\n\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E\n\n\n\n\u003Cp\u003EThe problem here is that the derivative corresponds to the recognizer. Parsers are a bit trickier, than recognizers.\u003C\u002Fp\u003E\n\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Flink.springer.com\u002Fchapter\u002F10.1007\u002F3-540-09510-1_39\"\u003ERuzzo in 1979\u003C\u002Fa\u003E showed that any recognizer can be transformed to parser with the overhead of \u003Ccode\u003EO(log n)\u003C\u002Fcode\u003E at most.\u003C\u002Fp\u003E\n\n\u003Cp\u003EWadler shows the importance of lazy evaluation in this approach. He reminds that this approach corresponds to recursive descent (with backtracking ?) e.g. it can’t handle left recursive grammars.\u003C\u002Fp\u003E\n\n\u003Ch2\u003E\n  \u003Ca name=\"parsing-with-derivatives\" href=\"#parsing-with-derivatives\" class=\"anchor\"\u003E\n  \u003C\u002Fa\u003E\n  Parsing with derivatives\n\u003C\u002Fh2\u003E\n\n\u003Cp\u003EThe idea was proposed by \u003Ca href=\"http:\u002F\u002Fdavid.darais.com\u002Fassets\u002Fpapers\u002Fparsing-with-derivatives\u002Fpwd.pdf\"\u003EMatthew Might et al in 2010\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\n\n\u003Cp\u003EThey extend the idea of Brzozowki derivative from regular to context-free languages. Then they create a set of functions that can be composed to represent grammars - the same way as in parser combinators. They rely on laziness and fixed point (essentially cycle detection) to make sure that the algorithm won’t do infinite recursion. Then they transform the recognizer into a parser and introduce the idea of derivative for the parser. And the last step is performance optimization - memoization is supposed to improve performance, but the problem is that on every parse it produces new grammar which grows exponentially (I guess exponentially). To solve the problem with growing grammar they added a compaction step after each parse cycle (Brzozowki had the same idea).\u003C\u002Fp\u003E\n\n\u003Cp\u003EWhat is good:\u003C\u002Fp\u003E\n\n\u003Cul\u003E\n\u003Cli\u003Esmall code size\u003C\u002Fli\u003E\n\u003Cli\u003Esupports CFG including left recursive grammars\u003C\u002Fli\u003E\n\u003Cli\u003Ecan handle ambiguous grammar - returns all possible parse trees\u003C\u002Fli\u003E\n\u003Cli\u003Eacceptable performance for such small code\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\n\u003Cp\u003EWhat is bad:\u003C\u002Fp\u003E\n\n\u003Cul\u003E\n\u003Cli\u003Eno error reporting - it either produces all possible parse trees or none\u003C\u002Fli\u003E\n\u003Cli\u003Enot so trivial to implement if the language doesn’t provide some features. More about this later.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\n\u003Cp\u003EThe initial intention was to \u003Ca href=\"http:\u002F\u002Fmatt.might.net\u002Farticles\u002Fparsing-with-derivatives\u002F\"\u003E“kill yacc”\u003C\u002Fa\u003E e.g. provide a simpler parsing algorithm (at least for learning purposes). It is indeed simple, but without fixing the problems listed above I don’t think it will “take over the world”.\u003C\u002Fp\u003E\n\n\u003Cp\u003EWhat else I would expect from parser - yacc is not that high bar IMO, it is based on LR algorithm from the ’60s, people since then invented a lot:\u003C\u002Fp\u003E\n\n\u003Cul\u003E\n\u003Cli\u003Enot optimal parse “forest” representation. It is represented as a set of all trees. For example, Spoofax produces one tree with special “ambiguity” nodes, which mark where ambiguity happened\u003C\u002Fli\u003E\n\u003Cli\u003Eno special way to resolve the ambiguity. For example, Spoofax, Marpa provide special instructions to mark associativity and precedence of operators\u003C\u002Fli\u003E\n\u003Cli\u003Eno special way to distinguish lexical and syntactical rules. For example, in Spoofax, ANTLR, and basically in all “scannerless” parsers this is possible\u003C\u002Fli\u003E\n\u003Cli\u003Eno error tolerance - it can’t be used to highlight code in IDE, which can be partially correct\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\n\u003Ch3\u003E\n  \u003Ca name=\"implementation\" href=\"#implementation\" class=\"anchor\"\u003E\n  \u003C\u002Fa\u003E\n  Implementation\n\u003C\u002Fh3\u003E\n\n\u003Cp\u003ECanonical implementation provided in \u003Ca href=\"https:\u002F\u002Fracket-lang.org\u002F\"\u003ERacket\u003C\u002Fa\u003E (Scheme). To make sure I understand how it works I decided to \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fstereobooster\u002Fparsing-with-derivalives\"\u003Ereimplement it in JavaScript\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\n\n\u003Cp\u003ELaziness is essential for this algorithm. Not a lot of languages provide it out of the box (in Scheme and Lisp it is trivial to emulate it with macros). In JS I decide to use Proxy and anonymous functions (lambdas).\u003C\u002Fp\u003E\n\n\u003Cp\u003ETo implement memoization we need to use a “hash map” (aka dictionary, aka associative array). Not all languages allow to use objects (aka structs) as keys, for example, I use \u003Ccode\u003EWeakMap\u003C\u002Fcode\u003E instead of \u003Ccode\u003EMap\u003C\u002Fcode\u003E in JS. Also, not all languages provide “weak” hash maps, which means that memory won’t be cleaned up by garbage collectors.\u003C\u002Fp\u003E\n\n\u003Cp\u003EJS doesn’t support recursive \u003Ccode\u003Elet\u003C\u002Fcode\u003E, so I implemented a special function \u003Ccode\u003Eletrec\u003C\u002Fcode\u003E to define recursive grammars.\u003C\u002Fp\u003E\n\n\u003Cp\u003EJS doesn’t provide ordered sets. I decided to avoid \u003Ccode\u003Enpm\u003C\u002Fcode\u003E packages, so I use an array and remove duplicates upon insertion.\u003C\u002Fp\u003E\n\n\u003Cp\u003EJS doesn’t provide functional pattern matching - I use \u003Ccode\u003Eswitch\u002Fcase\u003C\u002Fcode\u003E and \u003Ccode\u003Eif\u002Felse\u003C\u002Fcode\u003E instead 🤷‍♀️.\u003C\u002Fp\u003E\n\n\u003Cp\u003EIt takes some time to understand how to implement a feature that is not built in the language. It is hard to debug - I wasn’t sure if there was an error in the algorithm or my reimplementation of laziness, memoization.\u003C\u002Fp\u003E\n\n\u003Ch2\u003E\n  \u003Ca name=\"ps\" href=\"#ps\" class=\"anchor\"\u003E\n  \u003C\u002Fa\u003E\n  PS\n\u003C\u002Fh2\u003E\n\n\u003Cp\u003EOne way or another it was a good learning exercise. More thoughts after:\u003C\u002Fp\u003E\n\n\u003Cp\u003EI don’t understand yet is why Wadler says that parsing combinators are decent recursive \u003Cstrong\u003Ewith backtracking\u003C\u002Fstrong\u003E - it produces all parse trees. Backtracking corresponds to depth-first search, lookahead corresponds to breadth-first search, right? Does it make sense to differentiate backtracking for all branches and lookahead of infinite depth? They both will walk through all nodes in the graph eventually, but in a different order 🤔.\u003C\u002Fp\u003E\n\n\u003Cp\u003ELanguage can be defined in 3 ways:\u003C\u002Fp\u003E\n\n\u003Cul\u003E\n\u003Cli\u003Eas a set\u003C\u002Fli\u003E\n\u003Cli\u003Eas production rules (quadruple alphabet, terminals, non-terminals, and rules)\u003C\u002Fli\u003E\n\u003Cli\u003Eas a recognizer automata\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\n\u003Cp\u003EThe first definition is unique but impractical. The other two are not unique e.g. two different grammars can describe the same language, for example: \u003Ccode\u003ES → ε | aS\u003C\u002Fcode\u003E, \u003Ccode\u003ES → ε | Sa\u003C\u002Fcode\u003E, \u003Ccode\u003Ea*\u003C\u002Fcode\u003E.\u003C\u002Fp\u003E\n\n\u003Cp\u003EI wonder if this algorithm can be trivially implemented only in functional languages or not? If the answer is yes, does it mean that JS is not so “functional” as people tend to think 🤔?\u003C\u002Fp\u003E\n\n\u003Cp\u003EThis exercise shows how JS lags behind, especially in meta-programming and standard libraries. I wonder how easier it would be to implement in Python or Ruby, which provides better standard library and meta-programming facilities.\u003C\u002Fp\u003E\n\n";c.body_markdown="---\ntitle: Parsing with derivatives\npublished: true\ndate: 2021-02-27 12:15:47 UTC\ntags: computerscience,syntax,grammar,parser\ncanonical_url: https:\u002F\u002Fstereobooster.com\u002Fposts\u002Fparsing-with-derivatives\u002F\n---\n\nBased on:\n\n- [Theory of Computation (CS3102), Spring 2017](http:\u002F\u002Fwww.cs.virginia.edu\u002F~robins\u002Fcs3102\u002Fslides\u002FTheory_Slides_Formal_Languages_and_Machines_v52.pdf), videos are [here](http:\u002F\u002Fwww.cs.virginia.edu\u002F~robins\u002Fvideos.html)\n- [It’s Time for a New Old Language, 2017](https:\u002F\u002Fgroups.csail.mit.edu\u002Fmac\u002Fusers\u002Fgjs\u002F6.945\u002Freadings\u002FSteele-MIT-April-2017.pdf), [talk](https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=dCuZkaaou0Q) by Guy L. Steele Jr.\n- [Parsing with Derivatives, 2011](http:\u002F\u002Fmatt.might.net\u002Fpapers\u002Fmight2011derivatives.pdf) by Matthew Might, David Darais, Daniel Spiewak, [video](https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=ZzsK8Am6dKU).\n\n## History of notation\n\nAll material I have read on the subject use slightly different notation. Apparently, there is some history behind it.\n\nSlide 21 from Guy L. Steele Jr. presentation:\n\n- **1951** Stephen Kleene develops regular expressions to describe McCulloch-Pitts (1943) nerve nets (uses `∨` for choice; considers postfix `∗`, but decides to make it a binary operator to avoid having empty strings: `x∗y` means any number of copies of `x`, followed by `y`).\n- **1956** Journal publication of Kleene’s technical report: binary `∗` only.\n- **1958** Copi, Elgot, and Wright formulate REs using `·` and `∨` and postfix `∗`.\n- **1962** Janusz Brzozowki uses binary `+` for `∨` and introduces postfix `+`.\n- **1968** Ken Thompson’s paper “Regular Expression Search Algorithm” uses `|`.\n- **1973** Thompson creates `grep` from `ed` editor for use by Doug McIlroy.\n- **1975** Alfred Aho creates `egrep` (includes `( )`, `|`, `*`, `+`, `?`).\n- **1978** CMU Alphard project uses regular expressions with `*`, `+`, and `#`.\n- **1981** CMU FEG and IDL use regular expressions with `*`, `+`, and `?`.\n\nFor example, Robins (see [lecture notes from the previous post](https:\u002F\u002Fdev.to\u002Fstereobooster\u002Fnotes-on-parsing-theory-part-3-3248)) uses Brzozowki notation (`+` for union).\n\nMatthew Might (in Parsing with derivatives) uses a variation of Copi, Elgot, and Wright notation:\n\n- `◦` instead of `·`\n- `∪` instead of `∨`\n- uses `ϵ` - the same as Niklaus Wirth in “What can we do about the unnecessary diversity of notation for syntactic definitions?”\n\nAlmost everybody uses `*` the same way - postfix unary operator. The difference is that some notations use superscript and some use plain variation. To add more confusion: `ϵ`, `ε` are both the same Greek letter - epsilon - in different styles.\n\n**Here supposed to be table, but dev.to can't handle tables correctly**, so screenshot instead:\n\n![](https:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Farticles\u002F0mpktigfims1p97zd9e4.png)\n\n¹ approximation ² aka repetition ³ RE - regular expressions ⁴ [PCRE](http:\u002F\u002Fwww.pcre.org\u002Fcurrent\u002Fdoc\u002Fhtml\u002Fpcre2pattern.html#SEC1) - Perl Compatible Regular Expressions\n\n## Dynamic programming\n\nIn the context of programming, it is an optimization technique developed by Richard Bellman in the 1950s. It can be applied to a specific class of recursive problems. For example, calculation of Fibonacci numbers or finding the shortest path in a graph.\n\nIn general, it allows to turn algorithms with exponential complexity to polynomial complexity (but may require more space). I won’t go into more details - but very primitively it boils down to memoization and cycle detection.\n\nYou can watch [this MIT course](https:\u002F\u002Focw.mit.edu\u002Fcourses\u002Felectrical-engineering-and-computer-science\u002F6-006-introduction-to-algorithms-fall-2011\u002Flecture-videos\u002Flecture-19-dynamic-programming-i-fibonacci-shortest-paths\u002F) where it’s explained better.\n\n## Brzozowki derivative\n\nIn [1964 Brzozowki](http:\u002F\u002Fkrchowdhary.com\u002Fme-tfl\u002F5-derivatives-of-regex-brzozowski.pdf) proposed idea of derivatives for regular expressions. Note: he uses `λ` for `ϵ` and `φ` for `∅`.\n\nFormally derivative defined as `Dₐ(R) = { t | at ϵ R }`. Basically, it is the opposite of concatenation.\n\nFor example:\n\n- if we have language `{ abb, abc, bbb }`\n- derivative by `a` will give `{ bb, bc }`\n- then derivative by `b` will give `{ b, c }`\n- then derivative by `c` will give `{ ε }`\n\nMore formally:\n\n- `Dₐa = ϵ`\n- `Dₐb = ∅`\n  - `Dₐϵ = ∅`\n  - `Dₐ∅ = ∅`\n- `Dₐ(P*) = (DₐP)P*`\n- `Dₐ(PQ) = (DₐP)Q + δ(P)DₐQ`\n- `Dₐ(P+Q) = DₐP + DₐQ`\n\nBrzozowki shows how derivatives can be used to construct Mealy and Moore automata (finite state machines). Also, he shows how identity rules can be used to simplify automata.\n\n## Parser combinators\n\nIn [1985 Wadler](https:\u002F\u002Frkrishnan.org\u002Ffiles\u002Fwadler-1985.pdf) proposed to represent parsers as functions and to construct bigger parsers by composing functions. The key idea is to start from parsers for atomic languages:\n\n```haskell\n-- empty language\nfail xs       = []            -- Dx(∅)   = ∅\n-- trivial language - empty string\nempty v xs    = [(v, xs)]     -- Dϵ(P)   = P\n-- singleton language\nlit 'a' \"abc\" = [('a', \"bc\")] -- Da(abc) = bc\nlit 'b' \"abc\" = []            -- Db(abc) = ∅\n```\n\nAtomic languages as finite state machines:\n\n![](https:\u002F\u002Fstereobooster.com\u002Fposts\u002Fparsing-with-derivatives\u002F0.svg)\n\nThen atomic parsers can be composed with union (`alt`), concatenation (`seq`), and Kleene star (`rep`) to create parsers for “bigger” languages.\n\nIt is a bit harder to see correspondence of derivatives to those parsers:\n\n```haskell\nalt (lit 'a') (lit 'b') \"abc\" = [('a', \"bc\")]\nseq (lit 'a') (lit 'b') \"abc\" = [(\"ab\", \"c\")]\nrep (lit 'a') \"aac\"           = [(\"aa\", \"c\"), (\"a\", \"ac\"), (\"\", \"aac\")]\n```\n\nThe problem here is that the derivative corresponds to the recognizer. Parsers are a bit trickier, than recognizers.\n\n[Ruzzo in 1979](https:\u002F\u002Flink.springer.com\u002Fchapter\u002F10.1007\u002F3-540-09510-1_39) showed that any recognizer can be transformed to parser with the overhead of `O(log n)` at most.\n\nWadler shows the importance of lazy evaluation in this approach. He reminds that this approach corresponds to recursive descent (with backtracking ?) e.g. it can’t handle left recursive grammars.\n\n## Parsing with derivatives\n\nThe idea was proposed by [Matthew Might et al in 2010](http:\u002F\u002Fdavid.darais.com\u002Fassets\u002Fpapers\u002Fparsing-with-derivatives\u002Fpwd.pdf).\n\nThey extend the idea of Brzozowki derivative from regular to context-free languages. Then they create a set of functions that can be composed to represent grammars - the same way as in parser combinators. They rely on laziness and fixed point (essentially cycle detection) to make sure that the algorithm won’t do infinite recursion. Then they transform the recognizer into a parser and introduce the idea of derivative for the parser. And the last step is performance optimization - memoization is supposed to improve performance, but the problem is that on every parse it produces new grammar which grows exponentially (I guess exponentially). To solve the problem with growing grammar they added a compaction step after each parse cycle (Brzozowki had the same idea).\n\nWhat is good:\n\n- small code size\n- supports CFG including left recursive grammars\n- can handle ambiguous grammar - returns all possible parse trees\n- acceptable performance for such small code\n\nWhat is bad:\n\n- no error reporting - it either produces all possible parse trees or none\n- not so trivial to implement if the language doesn’t provide some features. More about this later.\n\nThe initial intention was to [“kill yacc”](http:\u002F\u002Fmatt.might.net\u002Farticles\u002Fparsing-with-derivatives\u002F) e.g. provide a simpler parsing algorithm (at least for learning purposes). It is indeed simple, but without fixing the problems listed above I don’t think it will “take over the world”.\n\nWhat else I would expect from parser - yacc is not that high bar IMO, it is based on LR algorithm from the ’60s, people since then invented a lot:\n\n- not optimal parse “forest” representation. It is represented as a set of all trees. For example, Spoofax produces one tree with special “ambiguity” nodes, which mark where ambiguity happened\n- no special way to resolve the ambiguity. For example, Spoofax, Marpa provide special instructions to mark associativity and precedence of operators\n- no special way to distinguish lexical and syntactical rules. For example, in Spoofax, ANTLR, and basically in all “scannerless” parsers this is possible\n- no error tolerance - it can’t be used to highlight code in IDE, which can be partially correct\n\n### Implementation\n\nCanonical implementation provided in [Racket](https:\u002F\u002Fracket-lang.org\u002F) (Scheme). To make sure I understand how it works I decided to [reimplement it in JavaScript](https:\u002F\u002Fgithub.com\u002Fstereobooster\u002Fparsing-with-derivalives).\n\nLaziness is essential for this algorithm. Not a lot of languages provide it out of the box (in Scheme and Lisp it is trivial to emulate it with macros). In JS I decide to use Proxy and anonymous functions (lambdas).\n\nTo implement memoization we need to use a “hash map” (aka dictionary, aka associative array). Not all languages allow to use objects (aka structs) as keys, for example, I use `WeakMap` instead of `Map` in JS. Also, not all languages provide “weak” hash maps, which means that memory won’t be cleaned up by garbage collectors.\n\nJS doesn’t support recursive `let`, so I implemented a special function `letrec` to define recursive grammars.\n\nJS doesn’t provide ordered sets. I decided to avoid `npm` packages, so I use an array and remove duplicates upon insertion.\n\nJS doesn’t provide functional pattern matching - I use `switch\u002Fcase` and `if\u002Felse` instead 🤷‍♀️.\n\nIt takes some time to understand how to implement a feature that is not built in the language. It is hard to debug - I wasn’t sure if there was an error in the algorithm or my reimplementation of laziness, memoization.\n\n## PS\n\nOne way or another it was a good learning exercise. More thoughts after:\n\nI don’t understand yet is why Wadler says that parsing combinators are decent recursive **with backtracking** - it produces all parse trees. Backtracking corresponds to depth-first search, lookahead corresponds to breadth-first search, right? Does it make sense to differentiate backtracking for all branches and lookahead of infinite depth? They both will walk through all nodes in the graph eventually, but in a different order 🤔.\n\nLanguage can be defined in 3 ways:\n\n- as a set\n- as production rules (quadruple alphabet, terminals, non-terminals, and rules)\n- as a recognizer automata\n\nThe first definition is unique but impractical. The other two are not unique e.g. two different grammars can describe the same language, for example: `S → ε | aS`, `S → ε | Sa`, `a*`.\n\nI wonder if this algorithm can be trivially implemented only in functional languages or not? If the answer is yes, does it mean that JS is not so “functional” as people tend to think 🤔?\n\nThis exercise shows how JS lags behind, especially in meta-programming and standard libraries. I wonder how easier it would be to implement in Python or Ruby, which provides better standard library and meta-programming facilities.";c.user={name:a,username:a,twitter_username:a,github_username:a,website_url:"https:\u002F\u002Fstereobooster.com",profile_image:"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--f8G7aoyB--\u002Fc_fill,f_auto,fl_progressive,h_640,q_auto,w_640\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Fuser\u002Fprofile_image\u002F94664\u002Fdd5f88a0-3b21-4a84-8dac-95a1f8d1fbb5.png",profile_image_90:"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--X2v6FiLG--\u002Fc_fill,f_auto,fl_progressive,h_90,q_auto,w_90\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Fuser\u002Fprofile_image\u002F94664\u002Fdd5f88a0-3b21-4a84-8dac-95a1f8d1fbb5.png"};return {data:[{}],fetch:{"data-v-25febe66:0":{article:c}},mutations:[["SET_CURRENT_ARTICLE",c]]}}("stereobooster",null,{},4,"2021-02-27T12:41:42Z","2021-02-27T12:15:47Z")));