__NUXT_JSONP__("/articles/rwilsonrelease/644781", (function(a,b,c,d){c.type_of="article";c.id=644781;c.title="Kubernetes Health Checks - 2 Ways to Improve Stability in Your Production Applications";c.description="Kubernetes Health Checks - 2 Ways to Improve Stability in Your Production Applications   Hea...";c.readable_publish_date="Mar 25";c.slug="kubernetes-health-checks-2-ways-to-improve-stability-in-your-production-applications-4dg5";c.path="\u002Frwilsonrelease\u002Fkubernetes-health-checks-2-ways-to-improve-stability-in-your-production-applications-4dg5";c.url="https:\u002F\u002Fdev.to\u002Frwilsonrelease\u002Fkubernetes-health-checks-2-ways-to-improve-stability-in-your-production-applications-4dg5";c.comments_count=0;c.public_reactions_count=d;c.collection_id=a;c.published_timestamp=b;c.positive_reactions_count=d;c.cover_image="https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--iSfbHYsl--\u002Fc_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Farticles\u002F3mh8v1fd4wmatv95x5za.jpg";c.social_image="https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--8DG92Wkp--\u002Fc_imagga_scale,f_auto,fl_progressive,h_500,q_auto,w_1000\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Farticles\u002F3mh8v1fd4wmatv95x5za.jpg";c.canonical_url="https:\u002F\u002Freleasehub.com\u002Fblog\u002Fkubernetes-health-checks-2-ways-to-improve-stability";c.created_at="2021-03-24T22:45:50Z";c.edited_at=a;c.crossposted_at=a;c.published_at=b;c.last_comment_at=b;c.reading_time_minutes=10;c.tag_list="kubernetes, sre, architecture";c.tags=["kubernetes","sre","architecture"];c.body_html="\u003Ch1\u003E\n  \u003Ca name=\"kubernetes-health-checks-2-ways-to-improve-stability-in-your-production-applications\" href=\"#kubernetes-health-checks-2-ways-to-improve-stability-in-your-production-applications\" class=\"anchor\"\u003E\n  \u003C\u002Fa\u003E\n  Kubernetes Health Checks - 2 Ways to Improve Stability in Your Production Applications\n\u003C\u002Fh1\u003E\n\n\u003Cp\u003EHealth checks are often a last-minute addition to your application stack, if they are even included at all. Advanced Site Reliability Engineering (SRE) practices try to push best practices (like health checks) forward so they are included early before applications are deployed. Many engineers know intuitively that health checks are important, but getting them implemented correctly—and keeping them up to date—is very hard. This article tries to document best practices for health checks, application development including SRE tenets, and how to improve the stability and even performance of your application when it runs in production.\u003C\u002Fp\u003E\n\n\u003Cp\u003EAt \u003Ca href=\"https:\u002F\u002Freleasehub.com\"\u003ERelease\u003C\u002Fa\u003E, we have \u003Ca href=\"https:\u002F\u002Freleasehub.com\u002Fblog\u002Fkubernetes-pods-advanced-concepts-explained\"\u003Epreviously written\u003C\u002Fa\u003E about how we monitor and configure applications so you can also read that blog post now or at a later time.\u003C\u002Fp\u003E\n\n\u003Ch2\u003E\n  \u003Ca name=\"costs-of-downtime-and-instability-in-production\" href=\"#costs-of-downtime-and-instability-in-production\" class=\"anchor\"\u003E\n  \u003C\u002Fa\u003E\n  Costs of Downtime and Instability in Production\n\u003C\u002Fh2\u003E\n\n\u003Cp\u003EDo you know how much it costs for your application to go offline? Don’t worry if you don’t—or can’t—know the exact figure: the important thing is to go through the mental process of estimating how much an outage or degradation to your application would “cost.” Costs are not only measured in currency, you need to also consider impacts to your brand, your Net Promoter Score (NPS), chatter online and on social media among customers and potential customers, and even negative reactions in the public media.\u003C\u002Fp\u003E\n\n\u003Cp\u003EI have worked in Site Reliability and DevOps my whole career and I have worked at many different companies whose responses for downtime ranged from the casual “our site will be back up eventually and we’ll be fine” to “we have lost $XXX per minute in revenue and we need to investigate methods for replacing that revenue”. No matter the response, I still did the best job my team and I could muster to keep the application and infrastructure services alive and well. There will always be bugs and issues with the code that is deployed and how it runs, however, if a problem occurs at a lower level in the application stack or in the infrastructure itself, then the application simply has no hope of servicing the needs of the consumers who visit your site.\u003C\u002Fp\u003E\n\n\u003Cp\u003EThe metaphor that I used often was one of cars driving on the motorway: if the roads are wet and slippery, then the cars will be unsafe and dangerous. When and if a crash occurs, then the roads will also be blocked and traffic will stop while the crash is cleaned up. It’s true that the cars may run out of gasoline, the drivers may get lost and go to the wrong destination, or the cars may not have good horsepower to drive quickly, but all of those factors are a higher order concern in the traffic stack. In this way, I saw my team’s and my job as keeping the roads as clear and safe and uncongested as possible so that the cars could operate at the best possible level.\u003C\u002Fp\u003E\n\n\u003Ch2\u003E\n  \u003Ca name=\"the-symptoms-are-the-disease\" href=\"#the-symptoms-are-the-disease\" class=\"anchor\"\u003E\n  \u003C\u002Fa\u003E\n  The Symptoms Are The Disease\n\u003C\u002Fh2\u003E\n\n\u003Cp\u003EVery early in the internet industry, the best practices for application stability were primitive and reactionary. Site reliability involved a manual post-mortem approach: finding out what happened and then applying monitoring and alerting on that behavior to alert an operator that something was wrong. The best practices at the time involved a team of on-call engineers and operators who would literally watch an application 24 hours a day, 365 days a year (one extra day for leap years) and respond within a certain timeframe (usually less than fifteen minutes) to manually investigate and fix any issues that came up. In some cases the “team” was actually one poor person tasked with the impossible job of being on-call indefinitely.\u003C\u002Fp\u003E\n\n\u003Cp\u003EThere are several drawbacks to this approach, not the least of which is the human toll such manual response takes and the unsustainable pace. The cost of the team, the cost of staff turnover and training, the losses due to turnaround time and missed calls, and the impact to end users were all huge reasons to implement a better solution.\u003C\u002Fp\u003E\n\n\u003Ch2\u003E\n  \u003Ca name=\"health-checks-to-the-rescue\" href=\"#health-checks-to-the-rescue\" class=\"anchor\"\u003E\n  \u003C\u002Fa\u003E\n  Health Checks to the Rescue\n\u003C\u002Fh2\u003E\n\n\u003Cp\u003EOne key initiative that came about in the early aughts was the concept of a health check in the load balancer. I was part of a team that worked with several major load balancer manufacturers to implement a way to not only route traffic to services in our application, but to add monitors and tests (even then we called them “health checks”) to the endpoints which would allow us to add or remove services that were not responding or were unhealthy. The concept was that a web application would respond on a well-known port and respond with a well-known response that proved the application was ready to serve traffic.\u003C\u002Fp\u003E\n\n\u003Cp\u003EFor example, we might query the backend service at \u003Ccode\u003Ehttp:\u002F\u002F192.168.0.10\u002Fhealth-check\u003C\u002Fcode\u003E and we expected the service to respond with a string like \u003Ccode\u003E200 OK\u003C\u002Fcode\u003E. This trivial example doesn’t sound like much until you realized that our end-goal was to actually perform some internal checks in the application which would allow us to do more than respond with a static string. For example, the application might check that the database is responding to a sample query that a table exists, and then the application could check that the CPU was at some nominal value. Therefore, the health check could be expanded to something like:\u003Cbr\u003E\n\u003C\u002Fp\u003E\n\n\u003Cdiv class=\"highlight js-code-highlight\"\u003E\n\u003Cpre class=\"highlight plaintext\"\u003E\u003Ccode\u003EHTTP\u002F1.0 200 OK\n\nChecking DB… ok\nChecking CPU… ok\nChecking User cache… ok\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Cdiv class=\"highlight__panel js-actions-panel\"\u003E\n\u003Cdiv class=\"highlight__panel-action js-fullscreen-code-action\"\u003E\n    \u003Csvg xmlns=\"http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg\" width=\"20px\" height=\"20px\" viewbox=\"0 0 24 24\" class=\"highlight-action crayons-icon highlight-action--fullscreen-on\"\u003E\u003Ctitle\u003EEnter fullscreen mode\u003C\u002Ftitle\u003E\n    \u003Cpath d=\"M16 3h6v6h-2V5h-4V3zM2 3h6v2H4v4H2V3zm18 16v-4h2v6h-6v-2h4zM4 19h4v2H2v-6h2v4z\"\u003E\u003C\u002Fpath\u003E\n\u003C\u002Fsvg\u003E\n\n    \u003Csvg xmlns=\"http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg\" width=\"20px\" height=\"20px\" viewbox=\"0 0 24 24\" class=\"highlight-action crayons-icon highlight-action--fullscreen-off\"\u003E\u003Ctitle\u003EExit fullscreen mode\u003C\u002Ftitle\u003E\n    \u003Cpath d=\"M18 7h4v2h-6V3h2v4zM8 9H2V7h4V3h2v6zm10 8v4h-2v-6h6v2h-4zM8 15v6H6v-4H2v-2h6z\"\u003E\u003C\u002Fpath\u003E\n\u003C\u002Fsvg\u003E\n\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E\n\n\n\n\u003Cp\u003EConversely, if something went wrong, the application could respond something like this:\u003Cbr\u003E\n\u003C\u002Fp\u003E\n\n\u003Cdiv class=\"highlight js-code-highlight\"\u003E\n\u003Cpre class=\"highlight plaintext\"\u003E\u003Ccode\u003EHTTP\u002F1.0 500 CRITICAL\n\nChecking DB... ok\nChecking CPU… ok\nChecking User cache… CORRUPTED\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Cdiv class=\"highlight__panel js-actions-panel\"\u003E\n\u003Cdiv class=\"highlight__panel-action js-fullscreen-code-action\"\u003E\n    \u003Csvg xmlns=\"http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg\" width=\"20px\" height=\"20px\" viewbox=\"0 0 24 24\" class=\"highlight-action crayons-icon highlight-action--fullscreen-on\"\u003E\u003Ctitle\u003EEnter fullscreen mode\u003C\u002Ftitle\u003E\n    \u003Cpath d=\"M16 3h6v6h-2V5h-4V3zM2 3h6v2H4v4H2V3zm18 16v-4h2v6h-6v-2h4zM4 19h4v2H2v-6h2v4z\"\u003E\u003C\u002Fpath\u003E\n\u003C\u002Fsvg\u003E\n\n    \u003Csvg xmlns=\"http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg\" width=\"20px\" height=\"20px\" viewbox=\"0 0 24 24\" class=\"highlight-action crayons-icon highlight-action--fullscreen-off\"\u003E\u003Ctitle\u003EExit fullscreen mode\u003C\u002Ftitle\u003E\n    \u003Cpath d=\"M18 7h4v2h-6V3h2v4zM8 9H2V7h4V3h2v6zm10 8v4h-2v-6h6v2h-4zM8 15v6H6v-4H2v-2h6z\"\u003E\u003C\u002Fpath\u003E\n\u003C\u002Fsvg\u003E\n\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E\n\n\n\n\u003Cp\u003EUsing the response code of 200 and looking for the string “OK” (for example), the load balancer manufacturers were able to remove a service from the backend pool, allowing other servers to accept requests and avoid servers that would otherwise have an error. Also, we could set a timeout so that the load balancer would consider no response to be an error. In this way, we can remove traffic from servers that were not responsive. The beauty of the system we were designing was that we were going to be able to monitor errors proactively and directly at the origin. The servers would be removed before they became a problem.\u003C\u002Fp\u003E\n\n\u003Cp\u003EWe would also use the same health check in our monitoring and alerting systems that we had perfected over the previous decades by manually watching them and using them for diagnosis. The difference is that we had more information about what was going wrong, and simultaneously we had more time to respond and properly diagnose the problems without affecting customers at all. Imagine the relief at not having to respond to every alert at 2AM within 15 minutes, but being able to automatically open a ticket to have a technician during the graveyard shift respond within the hour and restart the server and add it back to the pool.\u003C\u002Fp\u003E\n\n\u003Cp\u003EEven better, we were able to convince the load balancer manufacturers to implement an inline-retry policy based on the same idea. For example, if a live service request to a backend server failed with a 500 error code, the load balancer could not only remove the server from the pool, but it could retry the request one more time on a healthy server. With this technology, the loadbalancer could try to resolve the situation before the customer even noticed anything was wrong, and no human could be quicker.\u003C\u002Fp\u003E\n\n\u003Ch2\u003E\n  \u003Ca name=\"its-not-just-human-labor\" href=\"#its-not-just-human-labor\" class=\"anchor\"\u003E\n  \u003C\u002Fa\u003E\n  It’s Not Just Human Labor\n\u003C\u002Fh2\u003E\n\n\u003Cp\u003EWe did better than save human labor and effort in monitoring the systems and responding to problems. After implementing health checks on the load balancers and inside the application, we were able to reduce errors and outages to the point where we actually raised our traffic levels by a double-digit percentage, and also increased actual revenue by a measurable amount. Users who might have encountered an error and navigated away after a Google search were staying around to browse and (more importantly) make purchases. By further tweaking the load balancing algorithms to favor healthier (or faster) servers, we further increased this beneficial business result even further. Steady growth over time occurred as well, because Google saw improved signals from users and fewer errors and therefore moved the site up in rankings. This was a stunning and unexpected outcome that was attributed to removing errors and downtime from our application running with this infrastructure and by utilising SRE practices (long before the term was coined).\u003C\u002Fp\u003E\n\n\u003Ch2\u003E\n  \u003Ca name=\"the-modern-solutions\" href=\"#the-modern-solutions\" class=\"anchor\"\u003E\n  \u003C\u002Fa\u003E\n  The Modern Solutions\n\u003C\u002Fh2\u003E\n\n\u003Cp\u003EWith the advent of Kubernetes, the lessons learnt the hard way over the past few decades have been carried forward in architecting a resilient and reliable design for complex service interactions. Kubernetes uses the concepts of a probe to test the application for liveness and readiness (there is a third probe that tests for startup delay, but we’re skipping that for the purposes of this article). With these two probes, we can implement a solution that makes applications far more stable and reduces downtime and manual intervention.\u003C\u002Fp\u003E\n\n\u003Ch3\u003E\n  \u003Ca name=\"liveness-probes\" href=\"#liveness-probes\" class=\"anchor\"\u003E\n  \u003C\u002Fa\u003E\n  Liveness Probes\n\u003C\u002Fh3\u003E\n\n\u003Cp\u003EThe first solution is the liveness probe which has the job of figuring out if a service is responding properly and within a certain time frame so that it can be considered running properly. If the probes fail, then the pod is considered “dead” and the pod will be terminated and restarted somewhere else in the cluster. For example, a web server may have a memory leak and stop responding after a certain amount of time or number of requests have occurred. Another example might be a database that fills up a temporary disk space area and is unable to process further transactions until the space is cleared out.\u003C\u002Fp\u003E\n\n\u003Cp\u003EYou may be saying to yourself that these seem like errors that should be corrected and dealt with properly rather than simply killing the pod and waiting for it to be rescheduled somewhere else. You would be absolutely correct, but let me counter with a rhetorical question asking, “Given this error condition, what do you want me to do at 2AM when no one is available?” The liveness probes can be excellent at monitoring non-responsive servers without state, but may not be so great at monitoring and restarting services with state, like the database example I gave above. So we recommend using the liveness probe only if you feel it would help more than it would hurt. We also spend extra care and effort to ensure that the liveness probes are very forgiving so they do not trigger on false-positive alarms.\u003C\u002Fp\u003E\n\n\u003Cp\u003EAnother counter-argument to the “fix it” stance has to do with direct or indirect engineering costs and interacting with third party or open-source code. Trying to allocate resources to fully diagnose an intermittent problem, much less attempt to fix the problem can be difficult. In the case of a third party software or an open-source project where getting upstream fixes submitted, prioritized, approved, tested, and pulled back downstream can be enormously expensive and time consuming. Sometimes the answer really is “just restart it”.\u003C\u002Fp\u003E\n\n\u003Ch3\u003E\n  \u003Ca name=\"liveness-probes\" href=\"#liveness-probes\" class=\"anchor\"\u003E\n  \u003C\u002Fa\u003E\n  Liveness Probes\n\u003C\u002Fh3\u003E\n\n\u003Cp\u003EThe second solution is a readiness probe which is much like the solution I described earlier in this article with the load balancers. Indeed, the readiness probe does exactly what I’ve described: Kubernetes will periodically run a command to test the service running inside the container to gauge proper and timely responses. The ingress (just a fancy name for the load balancer) will not send traffic to this pod unless and until the readiness probe states that the service is ready for correct operation.\u003C\u002Fp\u003E\n\n\u003Cp\u003EThis helps in some scenarios where a web server may hit a threshold in connections or traffic levels where it may slow down or stop responding to new requests. It may be the case that the application simply cannot handle more than a certain number of transactions and so Kubernetes can use this signal to route traffic to another pod that is less busy. If this slow down or refusal to respond can be correlated with other metrics (like traffic volume, CPU utilization, etc.) then the horizontal pod autoscaler could trigger more resources to be added to the service.\u003C\u002Fp\u003E\n\n\u003Cp\u003EIn fact, we believe that readiness probes are so important to correct functioning of applications that we strongly recommend all services have a health check of some kind enabled and tested. We feel so strongly about this that we have considered making it a warning condition when no health check is configured on a running service in any of your environments at Release. Specifically, we could make readiness probes an opt out requirement rather than an opt in nicety.\u003C\u002Fp\u003E\n\n\u003Ch3\u003E\n  \u003Ca name=\"some-examples\" href=\"#some-examples\" class=\"anchor\"\u003E\n  \u003C\u002Fa\u003E\n  Some examples\n\u003C\u002Fh3\u003E\n\n\u003Cp\u003EHere are some actual examples of health checks that we have implemented for our customers. These examples are generic enough to be applied almost anywhere.\u003C\u002Fp\u003E\n\n\u003Cp\u003EIn this example we do a simple Nginx check on port 80 to ensure that the application is responding before we send traffic to the proxy.\u003Cbr\u003E\n\u003C\u002Fp\u003E\n\n\u003Cdiv class=\"highlight js-code-highlight\"\u003E\n\u003Cpre class=\"highlight yaml\"\u003E\u003Ccode\u003E \u003Cspan class=\"na\"\u003Ereadiness_probe\u003C\u002Fspan\u003E\u003Cspan class=\"pi\"\u003E:\u003C\u002Fspan\u003E\n   \u003Cspan class=\"na\"\u003Eexec\u003C\u002Fspan\u003E\u003Cspan class=\"pi\"\u003E:\u003C\u002Fspan\u003E\n     \u003Cspan class=\"na\"\u003Ecommand\u003C\u002Fspan\u003E\u003Cspan class=\"pi\"\u003E:\u003C\u002Fspan\u003E\n     \u003Cspan class=\"pi\"\u003E-\u003C\u002Fspan\u003E \u003Cspan class=\"s\"\u003Epsql\u003C\u002Fspan\u003E\n     \u003Cspan class=\"pi\"\u003E-\u003C\u002Fspan\u003E \u003Cspan class=\"s2\"\u003E\"\u003C\u002Fspan\u003E\u003Cspan class=\"s\"\u003E-h\"\u003C\u002Fspan\u003E\n     \u003Cspan class=\"pi\"\u003E-\u003C\u002Fspan\u003E \u003Cspan class=\"s\"\u003Elocalhost\u003C\u002Fspan\u003E\n     \u003Cspan class=\"pi\"\u003E-\u003C\u002Fspan\u003E \u003Cspan class=\"s2\"\u003E\"\u003C\u002Fspan\u003E\u003Cspan class=\"s\"\u003E-c\"\u003C\u002Fspan\u003E\n     \u003Cspan class=\"pi\"\u003E-\u003C\u002Fspan\u003E \u003Cspan class=\"s\"\u003ESELECT \u003C\u002Fspan\u003E\u003Cspan class=\"m\"\u003E1\u003C\u002Fspan\u003E\n   \u003Cspan class=\"na\"\u003Eperiod_seconds\u003C\u002Fspan\u003E\u003Cspan class=\"pi\"\u003E:\u003C\u002Fspan\u003E \u003Cspan class=\"m\"\u003E2\u003C\u002Fspan\u003E\n   \u003Cspan class=\"na\"\u003Etimeout_seconds\u003C\u002Fspan\u003E\u003Cspan class=\"pi\"\u003E:\u003C\u002Fspan\u003E \u003Cspan class=\"m\"\u003E2\u003C\u002Fspan\u003E\n   \u003Cspan class=\"na\"\u003Efailure_threshold\u003C\u002Fspan\u003E\u003Cspan class=\"pi\"\u003E:\u003C\u002Fspan\u003E \u003Cspan class=\"m\"\u003E30\u003C\u002Fspan\u003E\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Cdiv class=\"highlight__panel js-actions-panel\"\u003E\n\u003Cdiv class=\"highlight__panel-action js-fullscreen-code-action\"\u003E\n    \u003Csvg xmlns=\"http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg\" width=\"20px\" height=\"20px\" viewbox=\"0 0 24 24\" class=\"highlight-action crayons-icon highlight-action--fullscreen-on\"\u003E\u003Ctitle\u003EEnter fullscreen mode\u003C\u002Ftitle\u003E\n    \u003Cpath d=\"M16 3h6v6h-2V5h-4V3zM2 3h6v2H4v4H2V3zm18 16v-4h2v6h-6v-2h4zM4 19h4v2H2v-6h2v4z\"\u003E\u003C\u002Fpath\u003E\n\u003C\u002Fsvg\u003E\n\n    \u003Csvg xmlns=\"http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg\" width=\"20px\" height=\"20px\" viewbox=\"0 0 24 24\" class=\"highlight-action crayons-icon highlight-action--fullscreen-off\"\u003E\u003Ctitle\u003EExit fullscreen mode\u003C\u002Ftitle\u003E\n    \u003Cpath d=\"M18 7h4v2h-6V3h2v4zM8 9H2V7h4V3h2v6zm10 8v4h-2v-6h6v2h-4zM8 15v6H6v-4H2v-2h6z\"\u003E\u003C\u002Fpath\u003E\n\u003C\u002Fsvg\u003E\n\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E\n\n\n\n\u003Cp\u003EIn this example we perform a health check against an Elastic search node to ensure that the cluster is healthy before accepting traffic (which presumably cannot be processed yet). This is a straight port from the Docker Compose examples in the open source repositories.\u003Cbr\u003E\n\u003C\u002Fp\u003E\n\n\u003Cdiv class=\"highlight js-code-highlight\"\u003E\n\u003Cpre class=\"highlight yaml\"\u003E\u003Ccode\u003E\u003Cspan class=\"pi\"\u003E-\u003C\u002Fspan\u003E \u003Cspan class=\"na\"\u003Ename\u003C\u002Fspan\u003E\u003Cspan class=\"pi\"\u003E:\u003C\u002Fspan\u003E \u003Cspan class=\"s\"\u003Eelasticsearch\u003C\u002Fspan\u003E\n \u003Cspan class=\"na\"\u003Eimage\u003C\u002Fspan\u003E\u003Cspan class=\"pi\"\u003E:\u003C\u002Fspan\u003E \u003Cspan class=\"s\"\u003Edocker.elastic.co\u002Felasticsearch\u002Felasticsearch:7.9.2\u003C\u002Fspan\u003E\n \u003Cspan class=\"na\"\u003Eports\u003C\u002Fspan\u003E\u003Cspan class=\"pi\"\u003E:\u003C\u002Fspan\u003E\n \u003Cspan class=\"pi\"\u003E-\u003C\u002Fspan\u003E \u003Cspan class=\"na\"\u003Etype\u003C\u002Fspan\u003E\u003Cspan class=\"pi\"\u003E:\u003C\u002Fspan\u003E \u003Cspan class=\"s\"\u003Enode_port\u003C\u002Fspan\u003E\n   \u003Cspan class=\"na\"\u003Etarget_port\u003C\u002Fspan\u003E\u003Cspan class=\"pi\"\u003E:\u003C\u002Fspan\u003E \u003Cspan class=\"s1\"\u003E'\u003C\u002Fspan\u003E\u003Cspan class=\"s\"\u003E9200'\u003C\u002Fspan\u003E\n   \u003Cspan class=\"na\"\u003Eport\u003C\u002Fspan\u003E\u003Cspan class=\"pi\"\u003E:\u003C\u002Fspan\u003E \u003Cspan class=\"s1\"\u003E'\u003C\u002Fspan\u003E\u003Cspan class=\"s\"\u003E9200'\u003C\u002Fspan\u003E\n \u003Cspan class=\"na\"\u003Eliveness_probe\u003C\u002Fspan\u003E\u003Cspan class=\"pi\"\u003E:\u003C\u002Fspan\u003E\n   \u003Cspan class=\"na\"\u003Eexec\u003C\u002Fspan\u003E\u003Cspan class=\"pi\"\u003E:\u003C\u002Fspan\u003E\n     \u003Cspan class=\"na\"\u003Ecommand\u003C\u002Fspan\u003E\u003Cspan class=\"pi\"\u003E:\u003C\u002Fspan\u003E\n     \u003Cspan class=\"pi\"\u003E-\u003C\u002Fspan\u003E \u003Cspan class=\"s\"\u003Ecurl\u003C\u002Fspan\u003E\n     \u003Cspan class=\"pi\"\u003E-\u003C\u002Fspan\u003E \u003Cspan class=\"s2\"\u003E\"\u003C\u002Fspan\u003E\u003Cspan class=\"s\"\u003E--fail\"\u003C\u002Fspan\u003E\n     \u003Cspan class=\"pi\"\u003E-\u003C\u002Fspan\u003E \u003Cspan class=\"s\"\u003Elocalhost:9200\u002F_cluster\u002Fhealth\u003C\u002Fspan\u003E\n   \u003Cspan class=\"na\"\u003Etimeout_seconds\u003C\u002Fspan\u003E\u003Cspan class=\"pi\"\u003E:\u003C\u002Fspan\u003E \u003Cspan class=\"m\"\u003E2\u003C\u002Fspan\u003E\n   \u003Cspan class=\"na\"\u003Efailure_threshold\u003C\u002Fspan\u003E\u003Cspan class=\"pi\"\u003E:\u003C\u002Fspan\u003E \u003Cspan class=\"m\"\u003E3\u003C\u002Fspan\u003E\n   \u003Cspan class=\"na\"\u003Eperiod_seconds\u003C\u002Fspan\u003E\u003Cspan class=\"pi\"\u003E:\u003C\u002Fspan\u003E \u003Cspan class=\"m\"\u003E30\u003C\u002Fspan\u003E\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Cdiv class=\"highlight__panel js-actions-panel\"\u003E\n\u003Cdiv class=\"highlight__panel-action js-fullscreen-code-action\"\u003E\n    \u003Csvg xmlns=\"http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg\" width=\"20px\" height=\"20px\" viewbox=\"0 0 24 24\" class=\"highlight-action crayons-icon highlight-action--fullscreen-on\"\u003E\u003Ctitle\u003EEnter fullscreen mode\u003C\u002Ftitle\u003E\n    \u003Cpath d=\"M16 3h6v6h-2V5h-4V3zM2 3h6v2H4v4H2V3zm18 16v-4h2v6h-6v-2h4zM4 19h4v2H2v-6h2v4z\"\u003E\u003C\u002Fpath\u003E\n\u003C\u002Fsvg\u003E\n\n    \u003Csvg xmlns=\"http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg\" width=\"20px\" height=\"20px\" viewbox=\"0 0 24 24\" class=\"highlight-action crayons-icon highlight-action--fullscreen-off\"\u003E\u003Ctitle\u003EExit fullscreen mode\u003C\u002Ftitle\u003E\n    \u003Cpath d=\"M18 7h4v2h-6V3h2v4zM8 9H2V7h4V3h2v6zm10 8v4h-2v-6h6v2h-4zM8 15v6H6v-4H2v-2h6z\"\u003E\u003C\u002Fpath\u003E\n\u003C\u002Fsvg\u003E\n\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E\n\n\n\n\u003Cp\u003EThis example is good to show how a non-HTTP check for a postgres database can be used to ensure the database is up and responding to requests. Note that if this database is not clustered, then application database requests can fail when the health check fails. Your application will need to respond accordingly (either fail in turn to cascade a failover at a higher level, or perform some sort of mitigation so that a graceful failure happens). Recall that if this were a liveness probe, the postgres container would be killed and restarted, which may not be what you want at all.\u003Cbr\u003E\n\u003C\u002Fp\u003E\n\n\u003Cdiv class=\"highlight js-code-highlight\"\u003E\n\u003Cpre class=\"highlight yaml\"\u003E\u003Ccode\u003E \u003Cspan class=\"na\"\u003Ereadiness_probe\u003C\u002Fspan\u003E\u003Cspan class=\"pi\"\u003E:\u003C\u002Fspan\u003E\n   \u003Cspan class=\"na\"\u003Eexec\u003C\u002Fspan\u003E\u003Cspan class=\"pi\"\u003E:\u003C\u002Fspan\u003E\n     \u003Cspan class=\"na\"\u003Ecommand\u003C\u002Fspan\u003E\u003Cspan class=\"pi\"\u003E:\u003C\u002Fspan\u003E\n     \u003Cspan class=\"pi\"\u003E-\u003C\u002Fspan\u003E \u003Cspan class=\"s\"\u003Epsql\u003C\u002Fspan\u003E\n     \u003Cspan class=\"pi\"\u003E-\u003C\u002Fspan\u003E \u003Cspan class=\"s2\"\u003E\"\u003C\u002Fspan\u003E\u003Cspan class=\"s\"\u003E-h\"\u003C\u002Fspan\u003E\n     \u003Cspan class=\"pi\"\u003E-\u003C\u002Fspan\u003E \u003Cspan class=\"s\"\u003Elocalhost\u003C\u002Fspan\u003E\n     \u003Cspan class=\"pi\"\u003E-\u003C\u002Fspan\u003E \u003Cspan class=\"s2\"\u003E\"\u003C\u002Fspan\u003E\u003Cspan class=\"s\"\u003E-c\"\u003C\u002Fspan\u003E\n     \u003Cspan class=\"pi\"\u003E-\u003C\u002Fspan\u003E \u003Cspan class=\"s\"\u003ESELECT \u003C\u002Fspan\u003E\u003Cspan class=\"m\"\u003E1\u003C\u002Fspan\u003E\n   \u003Cspan class=\"na\"\u003Eperiod_seconds\u003C\u002Fspan\u003E\u003Cspan class=\"pi\"\u003E:\u003C\u002Fspan\u003E \u003Cspan class=\"m\"\u003E2\u003C\u002Fspan\u003E\n   \u003Cspan class=\"na\"\u003Etimeout_seconds\u003C\u002Fspan\u003E\u003Cspan class=\"pi\"\u003E:\u003C\u002Fspan\u003E \u003Cspan class=\"m\"\u003E2\u003C\u002Fspan\u003E\n   \u003Cspan class=\"na\"\u003Efailure_threshold\u003C\u002Fspan\u003E\u003Cspan class=\"pi\"\u003E:\u003C\u002Fspan\u003E \u003Cspan class=\"m\"\u003E30\u003C\u002Fspan\u003E\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Cdiv class=\"highlight__panel js-actions-panel\"\u003E\n\u003Cdiv class=\"highlight__panel-action js-fullscreen-code-action\"\u003E\n    \u003Csvg xmlns=\"http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg\" width=\"20px\" height=\"20px\" viewbox=\"0 0 24 24\" class=\"highlight-action crayons-icon highlight-action--fullscreen-on\"\u003E\u003Ctitle\u003EEnter fullscreen mode\u003C\u002Ftitle\u003E\n    \u003Cpath d=\"M16 3h6v6h-2V5h-4V3zM2 3h6v2H4v4H2V3zm18 16v-4h2v6h-6v-2h4zM4 19h4v2H2v-6h2v4z\"\u003E\u003C\u002Fpath\u003E\n\u003C\u002Fsvg\u003E\n\n    \u003Csvg xmlns=\"http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg\" width=\"20px\" height=\"20px\" viewbox=\"0 0 24 24\" class=\"highlight-action crayons-icon highlight-action--fullscreen-off\"\u003E\u003Ctitle\u003EExit fullscreen mode\u003C\u002Ftitle\u003E\n    \u003Cpath d=\"M18 7h4v2h-6V3h2v4zM8 9H2V7h4V3h2v6zm10 8v4h-2v-6h6v2h-4zM8 15v6H6v-4H2v-2h6z\"\u003E\u003C\u002Fpath\u003E\n\u003C\u002Fsvg\u003E\n\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E\n\n\n\n\u003Ch2\u003E\n  \u003Ca name=\"step-n-profit\" href=\"#step-n-profit\" class=\"anchor\"\u003E\n  \u003C\u002Fa\u003E\n  Step N, Profit\n\u003C\u002Fh2\u003E\n\n\u003Cp\u003EBy implementing either (or both!) of these health checks, you can not only reduce the amount of time humans have to spend monitoring and interfering with applications, but you can even dramatically improve your traffic response levels, response times, and performance. In some cases, you might even be able to measure the impact to your customers’ NPS and\u002For your company’s top and bottom line.\u003Cbr\u003E\nPhoto by \u003Ca href=\"https:\u002F\u002Funsplash.com\u002F@hush52?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\"\u003EHush Naidoo\u003C\u002Fa\u003E on \u003Ca href=\"https:\u002F\u002Funsplash.com\u002Fs\u002Fphotos\u002Fhealth?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\"\u003EUnsplash\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\n";c.body_markdown="---\ncanonical_url: https:\u002F\u002Freleasehub.com\u002Fblog\u002Fkubernetes-health-checks-2-ways-to-improve-stability\n---\n# Kubernetes Health Checks - 2 Ways to Improve Stability in Your Production Applications\n\nHealth checks are often a last-minute addition to your application stack, if they are even included at all. Advanced Site Reliability Engineering (SRE) practices try to push best practices (like health checks) forward so they are included early before applications are deployed. Many engineers know intuitively that health checks are important, but getting them implemented correctly—and keeping them up to date—is very hard. This article tries to document best practices for health checks, application development including SRE tenets, and how to improve the stability and even performance of your application when it runs in production.\n\nAt [Release](https:\u002F\u002Freleasehub.com), we have [previously written](https:\u002F\u002Freleasehub.com\u002Fblog\u002Fkubernetes-pods-advanced-concepts-explained) about how we monitor and configure applications so you can also read that blog post now or at a later time.\n##Costs of Downtime and Instability in Production\nDo you know how much it costs for your application to go offline? Don’t worry if you don’t—or can’t—know the exact figure: the important thing is to go through the mental process of estimating how much an outage or degradation to your application would “cost.” Costs are not only measured in currency, you need to also consider impacts to your brand, your Net Promoter Score (NPS), chatter online and on social media among customers and potential customers, and even negative reactions in the public media.\n\nI have worked in Site Reliability and DevOps my whole career and I have worked at many different companies whose responses for downtime ranged from the casual “our site will be back up eventually and we’ll be fine” to “we have lost $XXX per minute in revenue and we need to investigate methods for replacing that revenue”. No matter the response, I still did the best job my team and I could muster to keep the application and infrastructure services alive and well. There will always be bugs and issues with the code that is deployed and how it runs, however, if a problem occurs at a lower level in the application stack or in the infrastructure itself, then the application simply has no hope of servicing the needs of the consumers who visit your site.\n\nThe metaphor that I used often was one of cars driving on the motorway: if the roads are wet and slippery, then the cars will be unsafe and dangerous. When and if a crash occurs, then the roads will also be blocked and traffic will stop while the crash is cleaned up. It’s true that the cars may run out of gasoline, the drivers may get lost and go to the wrong destination, or the cars may not have good horsepower to drive quickly, but all of those factors are a higher order concern in the traffic stack. In this way, I saw my team’s and my job as keeping the roads as clear and safe and uncongested as possible so that the cars could operate at the best possible level.\n\n## The Symptoms Are The Disease\n\nVery early in the internet industry, the best practices for application stability were primitive and reactionary. Site reliability involved a manual post-mortem approach: finding out what happened and then applying monitoring and alerting on that behavior to alert an operator that something was wrong. The best practices at the time involved a team of on-call engineers and operators who would literally watch an application 24 hours a day, 365 days a year (one extra day for leap years) and respond within a certain timeframe (usually less than fifteen minutes) to manually investigate and fix any issues that came up. In some cases the “team” was actually one poor person tasked with the impossible job of being on-call indefinitely.\n\nThere are several drawbacks to this approach, not the least of which is the human toll such manual response takes and the unsustainable pace. The cost of the team, the cost of staff turnover and training, the losses due to turnaround time and missed calls, and the impact to end users were all huge reasons to implement a better solution.\n## Health Checks to the Rescue\nOne key initiative that came about in the early aughts was the concept of a health check in the load balancer. I was part of a team that worked with several major load balancer manufacturers to implement a way to not only route traffic to services in our application, but to add monitors and tests (even then we called them “health checks”) to the endpoints which would allow us to add or remove services that were not responding or were unhealthy. The concept was that a web application would respond on a well-known port and respond with a well-known response that proved the application was ready to serve traffic.\n\nFor example, we might query the backend service at `http:\u002F\u002F192.168.0.10\u002Fhealth-check` and we expected the service to respond with a string like `200 OK`. This trivial example doesn’t sound like much until you realized that our end-goal was to actually perform some internal checks in the application which would allow us to do more than respond with a static string. For example, the application might check that the database is responding to a sample query that a table exists, and then the application could check that the CPU was at some nominal value. Therefore, the health check could be expanded to something like:\n\n```\nHTTP\u002F1.0 200 OK\n\nChecking DB… ok\nChecking CPU… ok\nChecking User cache… ok\n```\n\nConversely, if something went wrong, the application could respond something like this:\n\n```\nHTTP\u002F1.0 500 CRITICAL\n\nChecking DB... ok\nChecking CPU… ok\nChecking User cache… CORRUPTED\n```\n\nUsing the response code of 200 and looking for the string “OK” (for example), the load balancer manufacturers were able to remove a service from the backend pool, allowing other servers to accept requests and avoid servers that would otherwise have an error. Also, we could set a timeout so that the load balancer would consider no response to be an error. In this way, we can remove traffic from servers that were not responsive. The beauty of the system we were designing was that we were going to be able to monitor errors proactively and directly at the origin. The servers would be removed before they became a problem.\n\nWe would also use the same health check in our monitoring and alerting systems that we had perfected over the previous decades by manually watching them and using them for diagnosis. The difference is that we had more information about what was going wrong, and simultaneously we had more time to respond and properly diagnose the problems without affecting customers at all. Imagine the relief at not having to respond to every alert at 2AM within 15 minutes, but being able to automatically open a ticket to have a technician during the graveyard shift respond within the hour and restart the server and add it back to the pool.\n\nEven better, we were able to convince the load balancer manufacturers to implement an inline-retry policy based on the same idea. For example, if a live service request to a backend server failed with a 500 error code, the load balancer could not only remove the server from the pool, but it could retry the request one more time on a healthy server. With this technology, the loadbalancer could try to resolve the situation before the customer even noticed anything was wrong, and no human could be quicker.\n## It’s Not Just Human Labor\nWe did better than save human labor and effort in monitoring the systems and responding to problems. After implementing health checks on the load balancers and inside the application, we were able to reduce errors and outages to the point where we actually raised our traffic levels by a double-digit percentage, and also increased actual revenue by a measurable amount. Users who might have encountered an error and navigated away after a Google search were staying around to browse and (more importantly) make purchases. By further tweaking the load balancing algorithms to favor healthier (or faster) servers, we further increased this beneficial business result even further. Steady growth over time occurred as well, because Google saw improved signals from users and fewer errors and therefore moved the site up in rankings. This was a stunning and unexpected outcome that was attributed to removing errors and downtime from our application running with this infrastructure and by utilising SRE practices (long before the term was coined).\n## The Modern Solutions\nWith the advent of Kubernetes, the lessons learnt the hard way over the past few decades have been carried forward in architecting a resilient and reliable design for complex service interactions. Kubernetes uses the concepts of a probe to test the application for liveness and readiness (there is a third probe that tests for startup delay, but we’re skipping that for the purposes of this article). With these two probes, we can implement a solution that makes applications far more stable and reduces downtime and manual intervention.\n### Liveness Probes\nThe first solution is the liveness probe which has the job of figuring out if a service is responding properly and within a certain time frame so that it can be considered running properly. If the probes fail, then the pod is considered “dead” and the pod will be terminated and restarted somewhere else in the cluster. For example, a web server may have a memory leak and stop responding after a certain amount of time or number of requests have occurred. Another example might be a database that fills up a temporary disk space area and is unable to process further transactions until the space is cleared out.\n\nYou may be saying to yourself that these seem like errors that should be corrected and dealt with properly rather than simply killing the pod and waiting for it to be rescheduled somewhere else. You would be absolutely correct, but let me counter with a rhetorical question asking, “Given this error condition, what do you want me to do at 2AM when no one is available?” The liveness probes can be excellent at monitoring non-responsive servers without state, but may not be so great at monitoring and restarting services with state, like the database example I gave above. So we recommend using the liveness probe only if you feel it would help more than it would hurt. We also spend extra care and effort to ensure that the liveness probes are very forgiving so they do not trigger on false-positive alarms.\n\nAnother counter-argument to the “fix it” stance has to do with direct or indirect engineering costs and interacting with third party or open-source code. Trying to allocate resources to fully diagnose an intermittent problem, much less attempt to fix the problem can be difficult. In the case of a third party software or an open-source project where getting upstream fixes submitted, prioritized, approved, tested, and pulled back downstream can be enormously expensive and time consuming. Sometimes the answer really is “just restart it”.\n### Liveness Probes\nThe second solution is a readiness probe which is much like the solution I described earlier in this article with the load balancers. Indeed, the readiness probe does exactly what I’ve described: Kubernetes will periodically run a command to test the service running inside the container to gauge proper and timely responses. The ingress (just a fancy name for the load balancer) will not send traffic to this pod unless and until the readiness probe states that the service is ready for correct operation.\n\nThis helps in some scenarios where a web server may hit a threshold in connections or traffic levels where it may slow down or stop responding to new requests. It may be the case that the application simply cannot handle more than a certain number of transactions and so Kubernetes can use this signal to route traffic to another pod that is less busy. If this slow down or refusal to respond can be correlated with other metrics (like traffic volume, CPU utilization, etc.) then the horizontal pod autoscaler could trigger more resources to be added to the service.\n\nIn fact, we believe that readiness probes are so important to correct functioning of applications that we strongly recommend all services have a health check of some kind enabled and tested. We feel so strongly about this that we have considered making it a warning condition when no health check is configured on a running service in any of your environments at Release. Specifically, we could make readiness probes an opt out requirement rather than an opt in nicety.\n### Some examples\nHere are some actual examples of health checks that we have implemented for our customers. These examples are generic enough to be applied almost anywhere.\n\nIn this example we do a simple Nginx check on port 80 to ensure that the application is responding before we send traffic to the proxy.\n\n```yaml\n readiness_probe:\n   exec:\n     command:\n     - psql\n     - \"-h\"\n     - localhost\n     - \"-c\"\n     - SELECT 1\n   period_seconds: 2\n   timeout_seconds: 2\n   failure_threshold: 30\n```\n\nIn this example we perform a health check against an Elastic search node to ensure that the cluster is healthy before accepting traffic (which presumably cannot be processed yet). This is a straight port from the Docker Compose examples in the open source repositories.\n\n```yaml\n- name: elasticsearch\n image: docker.elastic.co\u002Felasticsearch\u002Felasticsearch:7.9.2\n ports:\n - type: node_port\n   target_port: '9200'\n   port: '9200'\n liveness_probe:\n   exec:\n     command:\n     - curl\n     - \"--fail\"\n     - localhost:9200\u002F_cluster\u002Fhealth\n   timeout_seconds: 2\n   failure_threshold: 3\n   period_seconds: 30\n```\n\nThis example is good to show how a non-HTTP check for a postgres database can be used to ensure the database is up and responding to requests. Note that if this database is not clustered, then application database requests can fail when the health check fails. Your application will need to respond accordingly (either fail in turn to cascade a failover at a higher level, or perform some sort of mitigation so that a graceful failure happens). Recall that if this were a liveness probe, the postgres container would be killed and restarted, which may not be what you want at all.\n\n```yaml\n readiness_probe:\n   exec:\n     command:\n     - psql\n     - \"-h\"\n     - localhost\n     - \"-c\"\n     - SELECT 1\n   period_seconds: 2\n   timeout_seconds: 2\n   failure_threshold: 30\n```\n\n## Step N, Profit\nBy implementing either (or both!) of these health checks, you can not only reduce the amount of time humans have to spend monitoring and interfering with applications, but you can even dramatically improve your traffic response levels, response times, and performance. In some cases, you might even be able to measure the impact to your customers’ NPS and\u002For your company’s top and bottom line.\nPhoto by [Hush Naidoo](https:\u002F\u002Funsplash.com\u002F@hush52?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https:\u002F\u002Funsplash.com\u002Fs\u002Fphotos\u002Fhealth?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)";c.user={name:"Regis Wilson",username:"rwilsonrelease",twitter_username:a,github_username:"rwilson-release",website_url:"https:\u002F\u002Fwww.releasehub.com",profile_image:"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--zsp2ZvPb--\u002Fc_fill,f_auto,fl_progressive,h_640,q_auto,w_640\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Fuser\u002Fprofile_image\u002F536482\u002F46484a1a-e730-4d2a-a92d-3f9d21727be7.jpeg",profile_image_90:"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--mYuCX3Db--\u002Fc_fill,f_auto,fl_progressive,h_90,q_auto,w_90\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Fuser\u002Fprofile_image\u002F536482\u002F46484a1a-e730-4d2a-a92d-3f9d21727be7.jpeg"};return {data:[{}],fetch:{"data-v-25febe66:0":{article:c}},mutations:[["SET_CURRENT_ARTICLE",c]]}}(null,"2021-03-25T00:11:26Z",{},9)));