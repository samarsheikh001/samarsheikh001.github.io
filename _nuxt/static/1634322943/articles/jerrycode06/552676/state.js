window.__NUXT__=(function(a,b,c,d,e,f,g){return {staticAssetsBase:"\u002F_nuxt\u002Fstatic\u002F1634322943",layout:"default",error:a,state:{currentArticle:{type_of:"article",id:552676,title:"Web Automation with Puppeteer - Node JS ",description:"I have a question in my mind right now, \"Should I call this blog Web Automation or Web Scraping ?\" Le...",readable_publish_date:"Dec 25 '20",slug:"web-automation-with-puppeteer-node-js-4kg6",path:"\u002Fjerrycode06\u002Fweb-automation-with-puppeteer-node-js-4kg6",url:c,comments_count:d,public_reactions_count:e,collection_id:a,published_timestamp:b,positive_reactions_count:e,cover_image:"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--MZA7ETxu--\u002Fc_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fi\u002Fcrphsq85rsgrivdmntmj.jpg",social_image:"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--xqRU8fB_--\u002Fc_imagga_scale,f_auto,fl_progressive,h_500,q_auto,w_1000\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fi\u002Fcrphsq85rsgrivdmntmj.jpg",canonical_url:c,created_at:b,edited_at:"2020-12-26T07:59:26Z",crossposted_at:a,published_at:b,last_comment_at:"2021-07-13T10:04:14Z",reading_time_minutes:d,tag_list:"webdev, node, help",tags:["webdev","node",f],body_html:"\u003Cp\u003EI have a question in my mind right now, \"Should I call this blog \u003Cem\u003EWeb Automation\u003C\u002Fem\u003E or \u003Cem\u003EWeb Scraping\u003C\u002Fem\u003E ?\" Leave it for now.\u003C\u002Fp\u003E\n\n\u003Cp\u003E\u003Cstrong\u003E&lt; Hello World \u002F&gt;\u003C\u002Fstrong\u003E I suppose you are here because \"You search Puppeteer in dev.to\" or \"My Blog is trending right now\" but I am here to tell you about Web Automation or Web Scraping. When I first read about Web Scraping, I had a question \"In order to do these web automation or web scraping , Is Python only the language ?\" The answer is no and I am here to tell you how to do this with Javascipt.\u003C\u002Fp\u003E\n\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--3S8qmNvt--\u002Fc_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fi\u002Fdz5go698tg5ioaybwbvo.png\" class=\"article-body-image-wrapper\"\u003E\u003Cimg src=\"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--3S8qmNvt--\u002Fc_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fi\u002Fdz5go698tg5ioaybwbvo.png\" alt=\"Scraping Meme\" loading=\"lazy\"\u003E\u003C\u002Fa\u003E \u003C\u002Fp\u003E\n\n\u003Ch1\u003E\n  \u003Ca name=\"web-scraping\" href=\"#web-scraping\"\u003E\n  \u003C\u002Fa\u003E\n  Web Scraping\n\u003C\u002Fh1\u003E\n\n\u003Cp\u003E\u003Cstrong\u003EWeb Scraping\u003C\u002Fstrong\u003E is the process of extracting information from the internet, now the intention behind this can be research, education, business, analysis, and others. Basic web scraping script consists of a “crawler” that goes to the internet, surf around the web, and scrape information from given pages. We have gone over different web scraping tools by using programming languages and without programming like selenium, request, BeautifulSoup, MechanicalSoup, Parsehub, Diffbot, etc. It makes sense why everyone needs web scraping because it makes manual- data gathering processes very fast. And web scraping is the only solution when websites do not provide an API and data is needed. Collection of data from the web has various name like Web Scraping, Web Data Extraction &amp; Web Harvesting. These days everything &amp; everyone needs fuel to run. Data is the most precious fuel to run any organization. Finding the data is good; extracting it even better; doing it using automation is perfect. \u003C\u002Fp\u003E\n\n\u003Ch1\u003E\n  \u003Ca name=\"using-javascipt\" href=\"#using-javascipt\"\u003E\n  \u003C\u002Fa\u003E\n  Using Javascipt\n\u003C\u002Fh1\u003E\n\n\u003Cp\u003EIn this demonstration we are going to use Node JS and Puppeteer. \u003Ca href=\"https:\u002F\u002Fnodejs.org\u002Fen\u002F\"\u003ENode JS\u003C\u002Fa\u003E is a open source javascript run time environment built on \u003Ca href=\"https:\u002F\u002Fnodejs.dev\u002Flearn\u002Fthe-v8-javascript-engine\"\u003EChrome's V8\u003C\u002Fa\u003E javascript engine written in C++ which enables javascript to run on your machine rather than your browser console. It is capable of reading or writing files on server and used in networking.\u003C\u002Fp\u003E\n\n\u003Ch3\u003E\n  \u003Ca name=\"puppeteer\" href=\"#puppeteer\"\u003E\n  \u003C\u002Fa\u003E\n  Puppeteer\n\u003C\u002Fh3\u003E\n\n\u003Cp\u003EAccording to its official \u003Ca href=\"https:\u002F\u002Fpptr.dev\u002F\"\u003Edocumentation\u003C\u002Fa\u003E - \u003Cbr\u003E\n\u003Cem\u003EPuppeteer is a Node library which provides a high-level API to control Chrome or Chromium over the DevTools Protocol. Puppeteer runs headless by default, but can be configured to run full (non-headless) Chrome or Chromium.\u003C\u002Fem\u003E\u003Cbr\u003E\nLet's understand this one-by-one - \u003C\u002Fp\u003E\n\n\u003Cul\u003E\n\u003Cli\u003EIt is a node library \u003C\u002Fli\u003E\n\u003Cli\u003EPuppeteer provides us with a function to access Chrome or Chromium which in turn means we can automate anything we do on these browsers with it like emulating a key press, a click etc.\u003C\u002Fli\u003E\n\u003Cli\u003EBy headless, it means that the whole operation on the browser by puppeteer can be done without ANY GUI (Graphical User Interface) .\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\n\u003Cp\u003EUsing it we can Scare data from the internet, Create pdf from web pages, Take screenshots, Create automation testing and many more. \u003Cbr\u003E\nNow I think you are understanding the hard text of documentation right now. If not, wait for it you will understand when we do coding part. \u003C\u002Fp\u003E\n\u003Ch3\u003E\n  \u003Ca name=\"prerequisites\" href=\"#prerequisites\"\u003E\n  \u003C\u002Fa\u003E\n  Prerequisites\n\u003C\u002Fh3\u003E\n\n\u003Cp\u003EThis tutorial is beginner friendly, no advanced knowledge of code is required. If you’re following along you’ll need NodeJS installed, basic knowledge of the command line, knowledge of JavaScript and knowledge of the DOM. If you don't have Node JS installed download it from \u003Ca href=\"https:\u002F\u002Fnodejs.org\u002Fen\u002Fdownload\u002F\"\u003Ehere\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\n\u003Ch2\u003E\n  \u003Ca name=\"show-time\" href=\"#show-time\"\u003E\n  \u003C\u002Fa\u003E\n  Show Time\n\u003C\u002Fh2\u003E\n\u003Ch3\u003E\n  \u003Ca name=\"project-setup\" href=\"#project-setup\"\u003E\n  \u003C\u002Fa\u003E\n  \u003Cstrong\u003EProject Setup\u003C\u002Fstrong\u003E\n\u003C\u002Fh3\u003E\n\n\u003Cul\u003E\n\u003Cli\u003EMake a folder with any name \u003C\u002Fli\u003E\n\u003Cli\u003EOpen that folder in VS Code \u003C\u002Fli\u003E\n\u003Cli\u003EOpen terminal in VS Code and type \u003Ccode\u003Enpm init --yes\u003C\u002Fcode\u003E. This will generate a \u003Ccode\u003Epackage.json\u003C\u002Fcode\u003E for managing project dependencies like this -\n\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cdiv class=\"highlight js-code-highlight\"\u003E\n\u003Cpre class=\"highlight plaintext\"\u003E\u003Ccode\u003E{\n  \"name\": \"puppeteer-nodejs\",\n  \"version\": \"1.0.0\",\n  \"description\": \"\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"test\": \"echo \\\"Error: no test specified\\\" &amp;&amp; exit 1\"\n  },\n  \"keywords\": [],\n  \"author\": \"\",\n  \"license\": \"ISC\"\n}\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Cdiv class=\"highlight__panel js-actions-panel\"\u003E\n\u003Cdiv class=\"highlight__panel-action js-fullscreen-code-action\"\u003E\n    \u003Csvg xmlns=\"http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg\" width=\"20px\" height=\"20px\" viewbox=\"0 0 24 24\" class=\"highlight-action crayons-icon highlight-action--fullscreen-on\"\u003E\u003Ctitle\u003EEnter fullscreen mode\u003C\u002Ftitle\u003E\n    \u003Cpath d=\"M16 3h6v6h-2V5h-4V3zM2 3h6v2H4v4H2V3zm18 16v-4h2v6h-6v-2h4zM4 19h4v2H2v-6h2v4z\"\u003E\u003C\u002Fpath\u003E\n\u003C\u002Fsvg\u003E\n\n    \u003Csvg xmlns=\"http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg\" width=\"20px\" height=\"20px\" viewbox=\"0 0 24 24\" class=\"highlight-action crayons-icon highlight-action--fullscreen-off\"\u003E\u003Ctitle\u003EExit fullscreen mode\u003C\u002Ftitle\u003E\n    \u003Cpath d=\"M18 7h4v2h-6V3h2v4zM8 9H2V7h4V3h2v6zm10 8v4h-2v-6h6v2h-4zM8 15v6H6v-4H2v-2h6z\"\u003E\u003C\u002Fpath\u003E\n\u003C\u002Fsvg\u003E\n\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E\n\n\n\u003Cul\u003E\n\u003Cli\u003ENow install puppeteer by using command \u003Ccode\u003Enpm install puppeteer\u003C\u002Fcode\u003E or you can also see their \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fpuppeteer\u002Fpuppeteer\u002Fblob\u002Fmain\u002FREADME.md\"\u003Edocumentation\u003C\u002Fa\u003E and read the installation. \u003C\u002Fli\u003E\n\u003Cli\u003EAfter installing you can see the puppeteer in the dependencies in the \u003Ccode\u003Epackage.json\u003C\u002Fcode\u003E file like this -\n\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cdiv class=\"highlight js-code-highlight\"\u003E\n\u003Cpre class=\"highlight plaintext\"\u003E\u003Ccode\u003E{\n  \"name\": \"puppeteer-nodejs\",\n  \"version\": \"1.0.0\",\n  \"description\": \"\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"test\": \"echo \\\"Error: no test specified\\\" &amp;&amp; exit 1\"\n  },\n  \"keywords\": [],\n  \"author\": \"\",\n  \"license\": \"ISC\",\n  \"dependencies\": {\n    \"puppeteer\": \"^5.5.0\"\n  }\n}\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Cdiv class=\"highlight__panel js-actions-panel\"\u003E\n\u003Cdiv class=\"highlight__panel-action js-fullscreen-code-action\"\u003E\n    \u003Csvg xmlns=\"http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg\" width=\"20px\" height=\"20px\" viewbox=\"0 0 24 24\" class=\"highlight-action crayons-icon highlight-action--fullscreen-on\"\u003E\u003Ctitle\u003EEnter fullscreen mode\u003C\u002Ftitle\u003E\n    \u003Cpath d=\"M16 3h6v6h-2V5h-4V3zM2 3h6v2H4v4H2V3zm18 16v-4h2v6h-6v-2h4zM4 19h4v2H2v-6h2v4z\"\u003E\u003C\u002Fpath\u003E\n\u003C\u002Fsvg\u003E\n\n    \u003Csvg xmlns=\"http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg\" width=\"20px\" height=\"20px\" viewbox=\"0 0 24 24\" class=\"highlight-action crayons-icon highlight-action--fullscreen-off\"\u003E\u003Ctitle\u003EExit fullscreen mode\u003C\u002Ftitle\u003E\n    \u003Cpath d=\"M18 7h4v2h-6V3h2v4zM8 9H2V7h4V3h2v6zm10 8v4h-2v-6h6v2h-4zM8 15v6H6v-4H2v-2h6z\"\u003E\u003C\u002Fpath\u003E\n\u003C\u002Fsvg\u003E\n\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E\n\n\n\u003Cul\u003E\n\u003Cli\u003EAt last create you javascript file with any name, I personally prefer \u003Ccode\u003Eindex.js\u003C\u002Fcode\u003E.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Ch3\u003E\n  \u003Ca name=\"quickstart\" href=\"#quickstart\"\u003E\n  \u003C\u002Fa\u003E\n  Quickstart\n\u003C\u002Fh3\u003E\n\n\u003Cp\u003EWe will start with an easy example where we took screenshot of this \u003Ca href=\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FCoronavirus\"\u003ECorona Wikipedia Page\u003C\u002Fa\u003E. In the \u003Ccode\u003Eindex.js\u003C\u002Fcode\u003E file write this code which you can see in the example code of documentation.\u003Cbr\u003E\n\u003C\u002Fp\u003E\n\n\u003Cdiv class=\"highlight js-code-highlight\"\u003E\n\u003Cpre class=\"highlight plaintext\"\u003E\u003Ccode\u003Econst puppeteer = require(\"puppeteer\");\n\n(async () =&gt; {\n  const browser = await puppeteer.launch();\n  const page = await browser.newPage();\n  await page.goto(\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FCoronavirus\");\n  await page.screenshot({ path: \"corona-wiki.png\" });\n  await browser.close();\n})();\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Cdiv class=\"highlight__panel js-actions-panel\"\u003E\n\u003Cdiv class=\"highlight__panel-action js-fullscreen-code-action\"\u003E\n    \u003Csvg xmlns=\"http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg\" width=\"20px\" height=\"20px\" viewbox=\"0 0 24 24\" class=\"highlight-action crayons-icon highlight-action--fullscreen-on\"\u003E\u003Ctitle\u003EEnter fullscreen mode\u003C\u002Ftitle\u003E\n    \u003Cpath d=\"M16 3h6v6h-2V5h-4V3zM2 3h6v2H4v4H2V3zm18 16v-4h2v6h-6v-2h4zM4 19h4v2H2v-6h2v4z\"\u003E\u003C\u002Fpath\u003E\n\u003C\u002Fsvg\u003E\n\n    \u003Csvg xmlns=\"http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg\" width=\"20px\" height=\"20px\" viewbox=\"0 0 24 24\" class=\"highlight-action crayons-icon highlight-action--fullscreen-off\"\u003E\u003Ctitle\u003EExit fullscreen mode\u003C\u002Ftitle\u003E\n    \u003Cpath d=\"M18 7h4v2h-6V3h2v4zM8 9H2V7h4V3h2v6zm10 8v4h-2v-6h6v2h-4zM8 15v6H6v-4H2v-2h6z\"\u003E\u003C\u002Fpath\u003E\n\u003C\u002Fsvg\u003E\n\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E\n\n\n\n\u003Cp\u003ESo what this example does is it uses async \u003Ca href=\"https:\u002F\u002Fdeveloper.mozilla.org\u002Fen-US\u002Fdocs\u002FGlossary\u002FIIFE\"\u003EIIFE\u003C\u002Fa\u003E and wraps the whole script inside it . Now run this script by writing \u003Ccode\u003Enode index.js\u003C\u002Fcode\u003E in terminal of VS Code and you will see something like this. \u003C\u002Fp\u003E\n\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--LPvYXybS--\u002Fc_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fi\u002Fnisr2dng14hqn4gcksu8.jpg\" class=\"article-body-image-wrapper\"\u003E\u003Cimg src=\"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--LPvYXybS--\u002Fc_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fi\u002Fnisr2dng14hqn4gcksu8.jpg\" alt=\"Code Image\" loading=\"lazy\"\u003E\u003C\u002Fa\u003E \u003C\u002Fp\u003E\n\n\u003Cp\u003EIf everything went well You would see a new png file \u003Ccode\u003Ecorona-wiki.png\u003C\u002Fcode\u003E which contains the screenshot of our wikipedia page.\u003C\u002Fp\u003E\n\n\u003Ch3\u003E\n  \u003Ca name=\"explanation\" href=\"#explanation\"\u003E\n  \u003C\u002Fa\u003E\n  Explanation\n\u003C\u002Fh3\u003E\n\n\u003Cul\u003E\n\u003Cli\u003E\n\u003Ccode\u003Econst puppeteer = require(‘puppeteer’);\u003C\u002Fcode\u003E is used to import puppeteer, it is going to be the first line of your scraper.\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Ccode\u003Eawait puppeteer.launch();\u003C\u002Fcode\u003E is used to initiate a web browser or more specifically to create a browser instance you can open your browser in headless mode and non- headless mode using \u003Ccode\u003E{headless:false}\u003C\u002Fcode\u003E by default its true that means it will run browser processes in the background.\u003C\u002Fli\u003E\n\u003Cli\u003EWe use await to wrap method calls in an async function, which we immediately invoke.\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Ccode\u003EnewPage()\u003C\u002Fcode\u003E method is used to get the page object. \u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Ccode\u003Egoto()\u003C\u002Fcode\u003E method to surf that URL and load it in the browser. \u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Ccode\u003Escreenshot()\u003C\u002Fcode\u003E takes a path argument and returns a screenshot of the webpage in 800×600 px form in the local directory.\u003C\u002Fli\u003E\n\u003Cli\u003EOnce we are done with our script, we call \u003Ccode\u003Eclose()\u003C\u002Fcode\u003E method on the browser. \u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\n\u003Ch3\u003E\n  \u003Ca name=\"scraping-data-from-wikipedia\" href=\"#scraping-data-from-wikipedia\"\u003E\n  \u003C\u002Fa\u003E\n  Scraping Data from Wikipedia\n\u003C\u002Fh3\u003E\n\n\u003Cp\u003EWe will scrape some basic info from our Coronavirus Wikipedia page and output this in our console or you can put it in separate file(.txt, .dat, etc) like we did above. \u003Cbr\u003E\nFirst of all let's go to our wikipedia page and scroll down a little you will see some headings so here we are - \u003C\u002Fp\u003E\n\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--0xr2JM0O--\u002Fc_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fi\u002Ffgcrdkt28xptx1rrivj3.png\" class=\"article-body-image-wrapper\"\u003E\u003Cimg src=\"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--0xr2JM0O--\u002Fc_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fi\u002Ffgcrdkt28xptx1rrivj3.png\" alt=\"Blog Image 3\" loading=\"lazy\"\u003E\u003C\u002Fa\u003E \u003C\u002Fp\u003E\n\n\u003Cp\u003ENow we will collect these all heading from this page now right click and you will see \u003Cstrong\u003EInspect Element\u003C\u002Fstrong\u003E click it this will open your \u003Cstrong\u003EInpector\u003C\u002Fstrong\u003E. I am using Mozilla , you can Chrome also and the process is same because we just need some class-info from inspector. \u003C\u002Fp\u003E\n\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--tvSCEssk--\u002Fc_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fi\u002Fp8dhqahbu9kyr33s5163.jpg\" class=\"article-body-image-wrapper\"\u003E\u003Cimg src=\"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--tvSCEssk--\u002Fc_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fi\u002Fp8dhqahbu9kyr33s5163.jpg\" alt=\"Blog Image\" loading=\"lazy\"\u003E\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\n\u003Cp\u003EYou can see the Heading \u003Ccode\u003E&lt;h2&gt;\u003C\u002Fcode\u003E contains span of \u003Ccode\u003Eclass = \"mw-headline\"\u003C\u002Fcode\u003E and this class is common for all heading and it is our path to collect all headings. \u003C\u002Fp\u003E\n\n\u003Cp\u003EWe add this function in our code -\u003Cbr\u003E\n\u003C\u002Fp\u003E\n\n\u003Cdiv class=\"highlight js-code-highlight\"\u003E\n\u003Cpre class=\"highlight plaintext\"\u003E\u003Ccode\u003Econst result = await page.evaluate(() =&gt; {\n    let headingFromWeb = document.querySelectorAll(\".mw-headline\");\n    const headingList = [...headingFromWeb];\n    return headingList.map((h) =&gt; h.innerText);\n  });\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Cdiv class=\"highlight__panel js-actions-panel\"\u003E\n\u003Cdiv class=\"highlight__panel-action js-fullscreen-code-action\"\u003E\n    \u003Csvg xmlns=\"http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg\" width=\"20px\" height=\"20px\" viewbox=\"0 0 24 24\" class=\"highlight-action crayons-icon highlight-action--fullscreen-on\"\u003E\u003Ctitle\u003EEnter fullscreen mode\u003C\u002Ftitle\u003E\n    \u003Cpath d=\"M16 3h6v6h-2V5h-4V3zM2 3h6v2H4v4H2V3zm18 16v-4h2v6h-6v-2h4zM4 19h4v2H2v-6h2v4z\"\u003E\u003C\u002Fpath\u003E\n\u003C\u002Fsvg\u003E\n\n    \u003Csvg xmlns=\"http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg\" width=\"20px\" height=\"20px\" viewbox=\"0 0 24 24\" class=\"highlight-action crayons-icon highlight-action--fullscreen-off\"\u003E\u003Ctitle\u003EExit fullscreen mode\u003C\u002Ftitle\u003E\n    \u003Cpath d=\"M18 7h4v2h-6V3h2v4zM8 9H2V7h4V3h2v6zm10 8v4h-2v-6h6v2h-4zM8 15v6H6v-4H2v-2h6z\"\u003E\u003C\u002Fpath\u003E\n\u003C\u002Fsvg\u003E\n\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E\n\n\n\n\u003Cul\u003E\n\u003Cli\u003EWe are using \u003Ccode\u003Epage.evaluate()\u003C\u002Fcode\u003E function for this process and store it in a variable \u003Ccode\u003Eresult\u003C\u002Fcode\u003E.\u003C\u002Fli\u003E\n\u003Cli\u003EWe are selecting that class with \u003Ccode\u003Edocument.querySelectorAll(\".mw-headline\");\u003C\u002Fcode\u003E\n\u003C\u002Fli\u003E\n\u003Cli\u003EMake it an array using the \u003Ca href=\"https:\u002F\u002Fdeveloper.mozilla.org\u002Fen-US\u002Fdocs\u002FWeb\u002FJavaScript\u002FReference\u002FOperators\u002FSpread_syntax\"\u003Espread operator\u003C\u002Fa\u003E and store in other variable \u003Ccode\u003EheadingList\u003C\u002Fcode\u003E.\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Ca href=\"https:\u002F\u002Fdeveloper.mozilla.org\u002Fen-US\u002Fdocs\u002FWeb\u002FJavaScript\u002FReference\u002FGlobal_Objects\u002FArray\u002Fmap\"\u003EMap\u003C\u002Fa\u003E that array and return the inner text part which contains our Headings. \u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\n\u003Cp\u003EOur final code will look like this -\u003Cbr\u003E\n\u003C\u002Fp\u003E\n\n\u003Cdiv class=\"highlight js-code-highlight\"\u003E\n\u003Cpre class=\"highlight plaintext\"\u003E\u003Ccode\u003Econst puppeteer = require(\"puppeteer\");\n\n(async () =&gt; {\n  const browser = await puppeteer.launch();\n  const page = await browser.newPage();\n  await page.goto(\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FCoronavirus\");\n  const result = await page.evaluate(() =&gt; {\n    let headingFromWeb = document.querySelectorAll(\".mw-headline\");\n    const headingList = [...headingFromWeb];\n    return headingList.map((h) =&gt; h.innerText);\n  });\n\n  console.log(result);\n  await browser.close();\n})();\n\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Cdiv class=\"highlight__panel js-actions-panel\"\u003E\n\u003Cdiv class=\"highlight__panel-action js-fullscreen-code-action\"\u003E\n    \u003Csvg xmlns=\"http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg\" width=\"20px\" height=\"20px\" viewbox=\"0 0 24 24\" class=\"highlight-action crayons-icon highlight-action--fullscreen-on\"\u003E\u003Ctitle\u003EEnter fullscreen mode\u003C\u002Ftitle\u003E\n    \u003Cpath d=\"M16 3h6v6h-2V5h-4V3zM2 3h6v2H4v4H2V3zm18 16v-4h2v6h-6v-2h4zM4 19h4v2H2v-6h2v4z\"\u003E\u003C\u002Fpath\u003E\n\u003C\u002Fsvg\u003E\n\n    \u003Csvg xmlns=\"http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg\" width=\"20px\" height=\"20px\" viewbox=\"0 0 24 24\" class=\"highlight-action crayons-icon highlight-action--fullscreen-off\"\u003E\u003Ctitle\u003EExit fullscreen mode\u003C\u002Ftitle\u003E\n    \u003Cpath d=\"M18 7h4v2h-6V3h2v4zM8 9H2V7h4V3h2v6zm10 8v4h-2v-6h6v2h-4zM8 15v6H6v-4H2v-2h6z\"\u003E\u003C\u002Fpath\u003E\n\u003C\u002Fsvg\u003E\n\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E\n\n\n\n\u003Cp\u003EWe are showing our result in terminal that's why we are using \u003Ccode\u003Econsole.log(result);\u003C\u002Fcode\u003E. If you have done right till now then you will see output like this - \u003C\u002Fp\u003E\n\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--X2kMWkB8--\u002Fc_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fi\u002F3mpoco841yf5bc79t43z.jpg\" class=\"article-body-image-wrapper\"\u003E\u003Cimg src=\"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--X2kMWkB8--\u002Fc_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fi\u002F3mpoco841yf5bc79t43z.jpg\" alt=\"Blog Image\" loading=\"lazy\"\u003E\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\n\u003Cp\u003EIf you are seeing something like this then pat on your back you have done a great job, you did scraping from a famous site. If you don't understand some keywords first time, Don't worry I have attached the links where you can find great resource and read it on your own. \u003Cbr\u003E\nThere are many things to web scraping like going to different pages like IMDb, your college site, etc. Try out on your own read the documentation and you'll like puppeteer like me.\u003C\u002Fp\u003E\n\n\u003Cp\u003EThanks for reading this long post! I hope it helped you understand Web Scraping a little better. If you liked this post, then please do give me a few ❤️. You are welcome to comment and ask anything!\u003C\u002Fp\u003E\n\n",body_markdown:"I have a question in my mind right now, \"Should I call this blog *Web Automation* or *Web Scraping* ?\" Leave it for now.\n\n**\u003C Hello World \u002F\u003E** I suppose you are here because \"You search Puppeteer in dev.to\" or \"My Blog is trending right now\" but I am here to tell you about Web Automation or Web Scraping. When I first read about Web Scraping, I had a question \"In order to do these web automation or web scraping , Is Python only the language ?\" The answer is no and I am here to tell you how to do this with Javascipt.\n \n![Scraping Meme](https:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fi\u002Fdz5go698tg5ioaybwbvo.png) \n\n#Web Scraping \n**Web Scraping** is the process of extracting information from the internet, now the intention behind this can be research, education, business, analysis, and others. Basic web scraping script consists of a “crawler” that goes to the internet, surf around the web, and scrape information from given pages. We have gone over different web scraping tools by using programming languages and without programming like selenium, request, BeautifulSoup, MechanicalSoup, Parsehub, Diffbot, etc. It makes sense why everyone needs web scraping because it makes manual- data gathering processes very fast. And web scraping is the only solution when websites do not provide an API and data is needed. Collection of data from the web has various name like Web Scraping, Web Data Extraction & Web Harvesting. These days everything & everyone needs fuel to run. Data is the most precious fuel to run any organization. Finding the data is good; extracting it even better; doing it using automation is perfect. \n\n#Using Javascipt \nIn this demonstration we are going to use Node JS and Puppeteer. [Node JS](https:\u002F\u002Fnodejs.org\u002Fen\u002F) is a open source javascript run time environment built on [Chrome's V8](https:\u002F\u002Fnodejs.dev\u002Flearn\u002Fthe-v8-javascript-engine) javascript engine written in C++ which enables javascript to run on your machine rather than your browser console. It is capable of reading or writing files on server and used in networking.\n\n###Puppeteer \nAccording to its official [documentation](https:\u002F\u002Fpptr.dev\u002F) - \n*Puppeteer is a Node library which provides a high-level API to control Chrome or Chromium over the DevTools Protocol. Puppeteer runs headless by default, but can be configured to run full (non-headless) Chrome or Chromium.*\nLet's understand this one-by-one - \n * It is a node library \n * Puppeteer provides us with a function to access Chrome or Chromium which in turn means we can automate anything we do on these browsers with it like emulating a key press, a click etc.\n * By headless, it means that the whole operation on the browser by puppeteer can be done without ANY GUI (Graphical User Interface) .\n \nUsing it we can Scare data from the internet, Create pdf from web pages, Take screenshots, Create automation testing and many more. \nNow I think you are understanding the hard text of documentation right now. If not, wait for it you will understand when we do coding part. \n\n###Prerequisites\nThis tutorial is beginner friendly, no advanced knowledge of code is required. If you’re following along you’ll need NodeJS installed, basic knowledge of the command line, knowledge of JavaScript and knowledge of the DOM. If you don't have Node JS installed download it from [here](https:\u002F\u002Fnodejs.org\u002Fen\u002Fdownload\u002F).\n\n##Show Time \n###**Project Setup**\n* Make a folder with any name \n* Open that folder in VS Code \n* Open terminal in VS Code and type `npm init --yes`. This will generate a `package.json` for managing project dependencies like this - \n```\n{\n  \"name\": \"puppeteer-nodejs\",\n  \"version\": \"1.0.0\",\n  \"description\": \"\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\"\n  },\n  \"keywords\": [],\n  \"author\": \"\",\n  \"license\": \"ISC\"\n}\n```\n* Now install puppeteer by using command `npm install puppeteer` or you can also see their [documentation](https:\u002F\u002Fgithub.com\u002Fpuppeteer\u002Fpuppeteer\u002Fblob\u002Fmain\u002FREADME.md) and read the installation. \n* After installing you can see the puppeteer in the dependencies in the `package.json` file like this - \n```\n{\n  \"name\": \"puppeteer-nodejs\",\n  \"version\": \"1.0.0\",\n  \"description\": \"\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\"\n  },\n  \"keywords\": [],\n  \"author\": \"\",\n  \"license\": \"ISC\",\n  \"dependencies\": {\n    \"puppeteer\": \"^5.5.0\"\n  }\n}\n```\n* At last create you javascript file with any name, I personally prefer `index.js`.\n\n###Quickstart\nWe will start with an easy example where we took screenshot of this [Corona Wikipedia Page](https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FCoronavirus). In the `index.js` file write this code which you can see in the example code of documentation.\n```\nconst puppeteer = require(\"puppeteer\");\n\n(async () =\u003E {\n  const browser = await puppeteer.launch();\n  const page = await browser.newPage();\n  await page.goto(\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FCoronavirus\");\n  await page.screenshot({ path: \"corona-wiki.png\" });\n  await browser.close();\n})();\n```\nSo what this example does is it uses async [IIFE](https:\u002F\u002Fdeveloper.mozilla.org\u002Fen-US\u002Fdocs\u002FGlossary\u002FIIFE) and wraps the whole script inside it . Now run this script by writing `node index.js` in terminal of VS Code and you will see something like this. \n\n![Code Image](https:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fi\u002Fnisr2dng14hqn4gcksu8.jpg) \n\nIf everything went well You would see a new png file `corona-wiki.png` which contains the screenshot of our wikipedia page.\n\n###Explanation\n* `const puppeteer = require(‘puppeteer’);` is used to import puppeteer, it is going to be the first line of your scraper.\n* `await puppeteer.launch();` is used to initiate a web browser or more specifically to create a browser instance you can open your browser in headless mode and non- headless mode using `{headless:false}` by default its true that means it will run browser processes in the background.\n* We use await to wrap method calls in an async function, which we immediately invoke.\n* `newPage()` method is used to get the page object. \n* `goto()` method to surf that URL and load it in the browser. \n* `screenshot()` takes a path argument and returns a screenshot of the webpage in 800×600 px form in the local directory.\n* Once we are done with our script, we call `close()` method on the browser. \n\n###Scraping Data from Wikipedia\nWe will scrape some basic info from our Coronavirus Wikipedia page and output this in our console or you can put it in separate file(.txt, .dat, etc) like we did above. \nFirst of all let's go to our wikipedia page and scroll down a little you will see some headings so here we are - \n\n![Blog Image 3](https:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fi\u002Ffgcrdkt28xptx1rrivj3.png) \n\nNow we will collect these all heading from this page now right click and you will see **Inspect Element** click it this will open your **Inpector**. I am using Mozilla , you can Chrome also and the process is same because we just need some class-info from inspector. \n\n![Blog Image](https:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fi\u002Fp8dhqahbu9kyr33s5163.jpg)\n\nYou can see the Heading `\u003Ch2\u003E` contains span of `class = \"mw-headline\"` and this class is common for all heading and it is our path to collect all headings. \n\nWe add this function in our code - \n```\nconst result = await page.evaluate(() =\u003E {\n    let headingFromWeb = document.querySelectorAll(\".mw-headline\");\n    const headingList = [...headingFromWeb];\n    return headingList.map((h) =\u003E h.innerText);\n  });\n```\n* We are using `page.evaluate()` function for this process and store it in a variable `result`.\n* We are selecting that class with `document.querySelectorAll(\".mw-headline\");`\n* Make it an array using the [spread operator](https:\u002F\u002Fdeveloper.mozilla.org\u002Fen-US\u002Fdocs\u002FWeb\u002FJavaScript\u002FReference\u002FOperators\u002FSpread_syntax) and store in other variable `headingList`.\n* [Map](https:\u002F\u002Fdeveloper.mozilla.org\u002Fen-US\u002Fdocs\u002FWeb\u002FJavaScript\u002FReference\u002FGlobal_Objects\u002FArray\u002Fmap) that array and return the inner text part which contains our Headings. \n\nOur final code will look like this - \n```\nconst puppeteer = require(\"puppeteer\");\n\n(async () =\u003E {\n  const browser = await puppeteer.launch();\n  const page = await browser.newPage();\n  await page.goto(\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FCoronavirus\");\n  const result = await page.evaluate(() =\u003E {\n    let headingFromWeb = document.querySelectorAll(\".mw-headline\");\n    const headingList = [...headingFromWeb];\n    return headingList.map((h) =\u003E h.innerText);\n  });\n\n  console.log(result);\n  await browser.close();\n})();\n```\nWe are showing our result in terminal that's why we are using `console.log(result);`. If you have done right till now then you will see output like this - \n\n![Blog Image](https:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fi\u002F3mpoco841yf5bc79t43z.jpg)\n\nIf you are seeing something like this then pat on your back you have done a great job, you did scraping from a famous site. If you don't understand some keywords first time, Don't worry I have attached the links where you can find great resource and read it on your own. \nThere are many things to web scraping like going to different pages like IMDb, your college site, etc. Try out on your own read the documentation and you'll like puppeteer like me.\n\nThanks for reading this long post! I hope it helped you understand Web Scraping a little better. If you liked this post, then please do give me a few ❤️. You are welcome to comment and ask anything!",user:{name:"Nikhil Upadhyay",username:g,twitter_username:"_headless_coder",github_username:g,website_url:a,profile_image:"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--chvmd78J--\u002Fc_fill,f_auto,fl_progressive,h_640,q_auto,w_640\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Fuser\u002Fprofile_image\u002F393181\u002F70767937-a9be-4715-8e62-c6f16a4e4f09.jpeg",profile_image_90:"https:\u002F\u002Fres.cloudinary.com\u002Fpracticaldev\u002Fimage\u002Ffetch\u002Fs--RSjvXXZC--\u002Fc_fill,f_auto,fl_progressive,h_90,q_auto,w_90\u002Fhttps:\u002F\u002Fdev-to-uploads.s3.amazonaws.com\u002Fuploads\u002Fuser\u002Fprofile_image\u002F393181\u002F70767937-a9be-4715-8e62-c6f16a4e4f09.jpeg"},flare_tag:{name:f,bg_color_hex:"#ff3232",text_color_hex:"#ffffff"}}},serverRendered:true,routePath:"\u002Farticles\u002Fjerrycode06\u002F552676",config:{_app:{basePath:"\u002F",assetsPath:"\u002F_nuxt\u002F",cdnURL:a}}}}(null,"2020-12-25T20:59:35Z","https:\u002F\u002Fdev.to\u002Fjerrycode06\u002Fweb-automation-with-puppeteer-node-js-4kg6",6,45,"help","jerrycode06"));